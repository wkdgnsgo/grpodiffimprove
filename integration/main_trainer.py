"""
VLM GRPO Main Trainer
====================

ëª¨ë“  ì»´í¬ë„ŒíŠ¸ë¥¼ í†µí•©í•˜ì—¬ End-to-End VLM GRPO í•™ìŠµì„ ìˆ˜í–‰í•˜ëŠ” ë©”ì¸ ëª¨ë“ˆì…ë‹ˆë‹¤.

ì‹œìŠ¤í…œ êµ¬ì¡°:
User Prompt â†’ VLM â†’ Enhanced Prompt â†’ SD3 â†’ Image â†’ CLIP Reward â†’ GRPO Update

ì£¼ìš” ê¸°ëŠ¥:
1. ì „ì²´ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ë° ì„¤ì •
2. í•™ìŠµ ë£¨í”„ ì‹¤í–‰
3. ê²€ì¦ ë° í‰ê°€
4. ê²°ê³¼ ì €ì¥ ë° ì‹œê°í™”
5. Wandb í†µí•©

Author: AI Assistant
Date: 2025-01-22
"""

import os
import sys
import logging
import time
from typing import Dict, List, Optional, Any
from pathlib import Path
import json

# í”„ë¡œì íŠ¸ ê²½ë¡œ ì¶”ê°€
sys.path.append(str(Path(__file__).parent.parent))

# ê° ëª¨ë“ˆ ì„í¬íŠ¸
VLMWrapper = None
SD3Generator = None
CLIPRewardCalculator = None
MultiRewardCalculator = None
GRPOTrainer = None
GRPOConfig = None
PromptDataLoader = None
ValidationEvaluator = None
WandbLogger = None

try:
    from models.vlm_wrapper import VLMWrapper
except ImportError as e:
    print(f"âš ï¸ VLMWrapper import warning: {e}")

try:
    from models.sd_generator import SD3Generator  
except ImportError as e:
    print(f"âš ï¸ SD3Generator import warning: {e}")

try:
    from models.clip_reward import CLIPRewardCalculator, MultiRewardCalculator
except ImportError as e:
    print(f"âš ï¸ CLIP modules import warning: {e}")

try:
    from training.grpo_trainer import GRPOTrainer, GRPOConfig
except ImportError as e:
    print(f"âš ï¸ GRPO modules import warning: {e}")

try:
    from utils.data_loader import DataLoader
except ImportError as e:
    print(f"âš ï¸ DataLoader import warning: {e}")

try:
    from evaluation.validator import ValidationEvaluator
except ImportError as e:
    print(f"âš ï¸ Validator import warning: {e}")

try:
    from integration.wandb_logger import WandbLogger
except ImportError as e:
    print(f"âš ï¸ WandbLogger import warning: {e}")

logger = logging.getLogger(__name__)

class VLMGRPOSystem:
    """
    VLM GRPO ì „ì²´ ì‹œìŠ¤í…œì„ ê´€ë¦¬í•˜ëŠ” ë©”ì¸ í´ë˜ìŠ¤
    
    ì´ í´ë˜ìŠ¤ëŠ”:
    1. ëª¨ë“  ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™” ë° ì—°ê²°
    2. ì „ì²´ í•™ìŠµ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
    3. ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ ë° ë¡œê¹…
    4. ì²´í¬í¬ì¸íŠ¸ ê´€ë¦¬
    5. ê²°ê³¼ ë¶„ì„ ë° ì €ì¥
    """
    
    def __init__(self, config_path: str = "config/default_config.json"):
        """
        VLM GRPO System ì´ˆê¸°í™”
        
        Args:
            config_path (str): ì„¤ì • íŒŒì¼ ê²½ë¡œ
        """
        self.config_path = config_path
        self.config = self._load_config()
        
        # ë¡œê¹… ì„¤ì •
        self._setup_logging()
        
        # ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™”
        self.vlm = None
        self.sd_generator = None
        self.clip_calculator = None
        self.multi_reward_calculator = None
        self.grpo_trainer = None
        self.data_loader = None
        self.validator = None
        self.wandb_logger = None
        
        # í•™ìŠµ ìƒíƒœ
        self.training_stats = {
            'best_reward': float('-inf'),
            'total_iterations': 0,
            'total_time': 0.0
        }
        
        logger.info("ğŸš€ VLM GRPO System initialized")
    
    def _load_config(self) -> Dict[str, Any]:
        """ì„¤ì • íŒŒì¼ ë¡œë“œ"""
        try:
            with open(self.config_path, 'r', encoding='utf-8') as f:
                config = json.load(f)
            logger.info(f"ğŸ“„ Configuration loaded from {self.config_path}")
            return config
        except Exception as e:
            logger.error(f"âŒ Failed to load config: {e}")
            raise
    
    def _setup_logging(self):
        """ë¡œê¹… ì„¤ì •"""
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
            handlers=[
                logging.StreamHandler(),
                logging.FileHandler('vlm_grpo_training.log')
            ]
        )
    
    def initialize_components(self):
        """
        ëª¨ë“  ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™”
        
        ì´ ë©”ì„œë“œëŠ” ì‹œìŠ¤í…œì˜ ëª¨ë“  êµ¬ì„± ìš”ì†Œë¥¼ ìˆœì„œëŒ€ë¡œ ì´ˆê¸°í™”í•©ë‹ˆë‹¤:
        1. VLM (í”„ë¡¬í”„íŠ¸ ê°œì„ )
        2. SD3 Generator (ì´ë¯¸ì§€ ìƒì„±)
        3. CLIP Reward Calculator (ë³´ìƒ ê³„ì‚°)
        4. GRPO Trainer (ê°•í™”í•™ìŠµ)
        5. Data Loader (ë°ì´í„° ê´€ë¦¬)
        6. Validator (ê²€ì¦)
        7. Wandb Logger (ì‹¤í—˜ ì¶”ì )
        """
        try:
            logger.info("ğŸ”§ Initializing components...")
            
            # 1. VLM ì´ˆê¸°í™”
            logger.info("ğŸ“ Initializing VLM...")
            if VLMWrapper is None:
                raise ImportError("VLMWrapper not available. Please install required dependencies.")
            self.vlm = VLMWrapper(
                config_path=self.config_path,
                device=self.config['system_settings']['device'],
                max_new_tokens=self.config['generation_settings']['vlm_generation']['max_new_tokens'],
                temperature=self.config['generation_settings']['vlm_generation']['temperature'],
                top_p=self.config['generation_settings']['vlm_generation']['top_p']
            )
            
            # 2. SD3 Generator ì´ˆê¸°í™”
            logger.info("ğŸ¨ Initializing SD3 Generator...")
            if SD3Generator is None:
                raise ImportError("SD3Generator not available. Please install required dependencies.")
            self.sd_generator = SD3Generator(
                config_path=self.config_path,
                device=self.config['system_settings']['device'],
                height=self.config['generation_settings']['sd_generation']['height'],
                width=self.config['generation_settings']['sd_generation']['width'],
                num_inference_steps=self.config['generation_settings']['sd_generation']['num_inference_steps'],
                guidance_scale=self.config['generation_settings']['sd_generation']['guidance_scale']
            )
            
            # 3. CLIP Reward Calculator ì´ˆê¸°í™”
            logger.info("ğŸ† Initializing CLIP Reward Calculator...")
            if CLIPRewardCalculator is None:
                raise ImportError("CLIPRewardCalculator not available. Please install required dependencies.")
            self.clip_calculator = CLIPRewardCalculator(
                model_name=self.config['model_settings']['clip_model'],
                device=self.config['system_settings']['device'],
                reward_weights=self.config['reward_settings']['reward_weights']
            )
            
            # 4. Multi Reward Calculator ì´ˆê¸°í™”
            if MultiRewardCalculator is None:
                raise ImportError("MultiRewardCalculator not available. Please install required dependencies.")
            self.multi_reward_calculator = MultiRewardCalculator(
                self.clip_calculator
            )
            
            # 5. GRPO Trainer ì´ˆê¸°í™”
            logger.info("ğŸ¯ Initializing GRPO Trainer...")
            if GRPOTrainer is None or GRPOConfig is None:
                raise ImportError("GRPO modules not available. Please install required dependencies.")
            grpo_config = GRPOConfig(
                learning_rate=self.config['training_settings']['learning_rate'],
                group_size=self.config['training_settings']['group_size'],
                num_iterations=self.config['training_settings']['num_iterations'],
                grpo_epochs=self.config['training_settings']['grpo_epochs'],
                gamma=self.config['training_settings']['grpo_parameters']['gamma'],
                kl_beta=self.config['training_settings']['grpo_parameters']['kl_beta'],
                clip_epsilon=self.config['training_settings']['grpo_parameters']['clip_epsilon'],
                entropy_coeff=self.config['training_settings']['grpo_parameters']['entropy_coeff'],
                max_grad_norm=self.config['training_settings']['grpo_parameters']['max_grad_norm'],
                epsilon_std=self.config['training_settings']['grpo_parameters']['epsilon_std'],
                max_new_tokens=self.config['generation_settings']['vlm_generation']['max_new_tokens'],
                vocab_size=50000,  # GPT-2 ê¸°ë³¸ vocab í¬ê¸°
                max_sequence_length=100,  # ìµœëŒ€ ì‹œí€€ìŠ¤ ê¸¸ì´
                temperature=self.config['generation_settings']['vlm_generation']['temperature'],
                device=self.config['system_settings']['device']
            )
            self.grpo_trainer = GRPOTrainer(
                vlm_model=self.vlm,
                sd_generator=self.sd_generator,
                clip_reward=self.clip_calculator,
                config=grpo_config
            )
            
            # 6. Data Loader ì´ˆê¸°í™”
            logger.info("ğŸ“Š Initializing Data Loader...")
            try:
                self.data_loader = DataLoader(
                    train_data_path=self.config['data_settings']['train_data_path'],
                    val_data_path=self.config['data_settings']['val_data_path'],
                    batch_shuffle=self.config['data_settings']['batch_shuffle']
                )
            except Exception as e:
                logger.error(f"âŒ Data Loader initialization failed: {e}")
                self.data_loader = None
            
            # 7. Validator ì´ˆê¸°í™”
            logger.info("âœ… Initializing Validator...")
            if ValidationEvaluator is None:
                raise ImportError("ValidationEvaluator not available. Please install required dependencies.")
            self.validator = ValidationEvaluator(
                vlm=self.vlm,
                sd_generator=self.sd_generator,
                clip_calculator=self.clip_calculator
            )
            
            # 8. Wandb Logger ì´ˆê¸°í™” (ì„ íƒì )
            if self.config.get("wandb_settings", {}).get("use_wandb", False):
                logger.info("ğŸ“ˆ Initializing Wandb Logger...")
                if WandbLogger is None:
                    logger.warning("âš ï¸ WandbLogger not available, skipping wandb initialization")
                else:
                    self.wandb_logger = WandbLogger(
                        project=self.config.get("wandb_settings", {}).get("project", "vlm-grpo"),
                        entity=self.config.get("wandb_settings", {}).get("entity", None),
                        config=self.config
                    )
            
            # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
            os.makedirs(self.config["output_settings"]["output_dir"], exist_ok=True)
            
            # í•™ìŠµ í†µê³„ ì´ˆê¸°í™”
            self.training_stats = {
                'best_reward': float('-inf'),
                'total_iterations': 0,
                'total_time': 0.0
            }
            
            logger.info("âœ… All components initialized successfully")
            
        except Exception as e:
            logger.error(f"âŒ Component initialization failed: {e}")
            raise
    
    def run_training(self):
        """
        ë©”ì¸ í•™ìŠµ ë£¨í”„ ì‹¤í–‰
        
        ì´ ë©”ì„œë“œëŠ” GRPO í•™ìŠµì˜ ì „ì²´ ê³¼ì •ì„ ì‹¤í–‰í•©ë‹ˆë‹¤:
        1. í•™ìŠµ ë°ì´í„° ë°°ì¹˜ ìƒì„±
        2. VLMìœ¼ë¡œ í”„ë¡¬í”„íŠ¸ ê°œì„ 
        3. SD3ë¡œ ì´ë¯¸ì§€ ìƒì„±
        4. CLIPìœ¼ë¡œ ë³´ìƒ ê³„ì‚°
        5. GRPO ì •ì±… ì—…ë°ì´íŠ¸
        6. ì£¼ê¸°ì  ê²€ì¦ ë° ì €ì¥
        """
        logger.info("ğŸš€ Starting VLM GRPO training...")
        self.start_time = time.time()
        
        try:
            for iteration in range(self.config["training_settings"]["num_iterations"]):
                iteration_start = time.time()
                
                logger.info(f"ğŸ”„ Iteration {iteration + 1}/{self.config['training_settings']['num_iterations']}")
                
                # 1. í•™ìŠµ ë°°ì¹˜ ìƒì„±
                if self.data_loader is None:
                    logger.error("âŒ Data loader not initialized")
                    break
                    
                batch_prompts = self.data_loader.get_training_batch(
                    batch_size=self.config["training_settings"]["group_size"]
                )
                
                if not batch_prompts:
                    logger.warning("âš ï¸ No training data available, skipping iteration")
                    continue
                
                # 2. GRPO ê·¸ë£¹ ë°ì´í„° ìˆ˜ì§‘ (í† í°ë³„ ìˆœì°¨ ìƒì„±)
                if self.grpo_trainer is None:
                    logger.error("âŒ GRPO trainer not initialized")
                    break
                
                # GRPOTrainerì˜ collect_group_data ë©”ì„œë“œ ì‚¬ìš©
                group_data = self.grpo_trainer.collect_group_data(batch_prompts)
                
                # 3. GRPO ì—…ë°ì´íŠ¸
                training_metrics = self.grpo_trainer.grpo_update(group_data)
                
                # 4. ë©”íŠ¸ë¦­ ë¡œê¹…
                iteration_time = time.time() - iteration_start
                self._log_training_metrics(iteration + 1, training_metrics, iteration_time)
                
                # 5. ì£¼ê¸°ì  ê²€ì¦
                if (iteration + 1) % self.config["training_settings"]["validation_interval"] == 0:
                    self._run_validation(iteration + 1)
                
                # 6. ì²´í¬í¬ì¸íŠ¸ ì €ì¥
                if (iteration + 1) % self.config["training_settings"]["checkpoint_interval"] == 0:
                    self._save_checkpoint(iteration + 1)
                
                # 7. ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ì €ì¥
                avg_reward = training_metrics.get('avg_reward', 0)
                if avg_reward > self.training_stats['best_reward']:
                    self.training_stats['best_reward'] = avg_reward
                    self._save_best_model(iteration + 1)
            
            # í•™ìŠµ ì™„ë£Œ
            total_time = time.time() - self.start_time
            self.training_stats['total_time'] = total_time
            
            logger.info(f"âœ… Training completed! Total time: {total_time:.2f}s")
            self._save_final_results()
            
        except Exception as e:
            logger.error(f"âŒ Training failed: {e}")
            raise
        finally:
            # Wandb ì„¸ì…˜ ì¢…ë£Œ
            if hasattr(self, 'wandb_logger') and self.wandb_logger:
                self.wandb_logger.finish()
    
    def _collect_training_data(self, prompts: List[str]) -> Dict[str, Any]:
        """
        í•™ìŠµ ë°ì´í„° ìˆ˜ì§‘: VLM + SD3 + CLIP íŒŒì´í”„ë¼ì¸
        
        Args:
            prompts (List[str]): ì…ë ¥ í”„ë¡¬í”„íŠ¸ë“¤
            
        Returns:
            Dict[str, Any]: ìˆ˜ì§‘ëœ í•™ìŠµ ë°ì´í„°
        """
        logger.debug(f"ğŸ“Š Collecting training data for {len(prompts)} prompts")
        
        group_data = {
            'prompts': prompts,
            'enhanced_prompts': [],
            'images': [],
            'rewards': [],
            'comprehensive_rewards': []
        }
        
        for prompt in prompts:
            try:
                # 1. VLMìœ¼ë¡œ í”„ë¡¬í”„íŠ¸ ê°œì„ 
                if self.vlm is None:
                    logger.warning("âš ï¸ VLM not initialized, using original prompt")
                    enhanced_prompt = prompt
                else:
                    enhanced_prompt = self.vlm.enhance_prompt(prompt)
                
                # 2. SD3ë¡œ ì´ë¯¸ì§€ ìƒì„±
                if self.sd_generator is None:
                    logger.warning("âš ï¸ SD generator not initialized, skipping image generation")
                    image = None
                else:
                    image = self.sd_generator.generate_image(enhanced_prompt)
                
                # 3. ì¢…í•©ì  ë³´ìƒ ê³„ì‚°
                if self.multi_reward_calculator is None:
                    logger.warning("âš ï¸ Multi reward calculator not initialized, using default reward")
                    rewards = {'final_reward': 0.0}
                else:
                    rewards = self.multi_reward_calculator.calculate_comprehensive_reward(
                        image, prompt, enhanced_prompt
                    )
                
                # ë°ì´í„° ì €ì¥
                group_data['enhanced_prompts'].append(enhanced_prompt)
                group_data['images'].append(image)
                group_data['rewards'].append(rewards['final_reward'])
                group_data['comprehensive_rewards'].append(rewards)
                
                logger.debug(f"âœ… Processed: '{prompt}' â†’ reward: {rewards['final_reward']:.4f}")
                
            except Exception as e:
                logger.warning(f"âš ï¸ Failed to process prompt '{prompt}': {e}")
                # ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ê°’ ì‚¬ìš©
                group_data['enhanced_prompts'].append(prompt)
                group_data['images'].append(None)
                group_data['rewards'].append(0.0)
                group_data['comprehensive_rewards'].append({'final_reward': 0.0})
        
        return group_data
    
    def _log_training_metrics(self, iteration: int, metrics: Dict, iteration_time: float):
        """
        í•™ìŠµ ë©”íŠ¸ë¦­ ë¡œê¹…
        
        Args:
            iteration (int): í˜„ì¬ ë°˜ë³µ íšŸìˆ˜
            metrics (Dict): í•™ìŠµ ë©”íŠ¸ë¦­
            iteration_time (float): ë°˜ë³µ ì‹œê°„
        """
        # ê¸°ë³¸ ë¡œê¹…
        logger.info(f"ğŸ“Š Iteration {iteration} metrics:")
        logger.info(f"  - Policy Loss: {metrics.get('policy_loss', 0):.6f}")
        logger.info(f"  - KL Divergence: {metrics.get('kl_div', 0):.6f}")
        logger.info(f"  - Entropy: {metrics.get('entropy', 0):.6f}")
        logger.info(f"  - Average Reward: {metrics.get('avg_reward', 0):.4f}")
        logger.info(f"  - Iteration Time: {iteration_time:.2f}s")
        
        # Wandb ë¡œê¹…
        if self.wandb_logger:
            wandb_metrics = {
                'iteration': iteration,
                'policy_loss': metrics.get('policy_loss', 0),
                'kl_divergence': metrics.get('kl_div', 0),
                'entropy': metrics.get('entropy', 0),
                'average_reward': metrics.get('avg_reward', 0),
                'iteration_time': iteration_time,
                'total_time': time.time() - self.start_time if hasattr(self, 'start_time') else 0
            }
            self.wandb_logger.log_training_metrics(wandb_metrics)
    
    def _run_validation(self, iteration: int):
        """
        ê²€ì¦ ì‹¤í–‰
        
        Args:
            iteration (int): í˜„ì¬ ë°˜ë³µ íšŸìˆ˜
        """
        logger.info(f"ğŸ” Running validation at iteration {iteration}")
        
        try:
            # ê²€ì¦ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
            if self.data_loader is None:
                logger.warning("âš ï¸ Data loader not initialized, skipping validation")
                return
                
            val_data = self.data_loader.get_validation_data()
            
            if not val_data:
                logger.warning("âš ï¸ No validation data available")
                return
            
            # ê²€ì¦ ì‹¤í–‰ (ì´ë¯¸ì§€ ì €ì¥ í¬í•¨)
            if self.validator is None:
                logger.warning("âš ï¸ Validator not initialized, skipping validation")
                return
            
            # ì´ë¯¸ì§€ ì €ì¥ ì„¤ì • í™•ì¸
            save_images = self.config.get("output_settings", {}).get("save_images", True)
            output_dir = self.config.get("output_settings", {}).get("output_dir", "vlm_grpo_results")
            
            val_results = self.validator.evaluate_batch(
                val_data[:10],  # ì²˜ìŒ 10ê°œë§Œ
                save_images=save_images,
                output_dir=output_dir,
                iteration=iteration
            )
            
            # ê²°ê³¼ ë¡œê¹…
            logger.info(f"ğŸ“Š Validation Results (Iteration {iteration}):")
            for metric, value in val_results.items():
                if isinstance(value, (int, float)):
                    logger.info(f"  - {metric}: {value:.4f}")
            
            # ì´ë¯¸ì§€ ì €ì¥ ê²°ê³¼ ë¡œê¹…
            if save_images and val_results.get('saved_images'):
                saved_count = len(val_results['saved_images'])
                logger.info(f"ğŸ’¾ Saved {saved_count} validation images")
                
                # ì €ì¥ëœ ì´ë¯¸ì§€ ì •ë³´ ë¡œê¹… (ì²˜ìŒ 3ê°œë§Œ)
                for i, img_info in enumerate(val_results['saved_images'][:3]):
                    logger.info(f"  ğŸ“¸ Image {i+1}:")
                    logger.info(f"    Original: '{img_info['prompt'][:30]}...'")
                    logger.info(f"    Enhanced: '{img_info['enhanced_prompt'][:50]}...'")
                    logger.info(f"    Enhanced Path: {img_info['image_path']}")
                    if 'saved_original_path' in img_info:
                        logger.info(f"    Original Path: {img_info['saved_original_path']}")
                    if 'saved_prompts_path' in img_info:
                        logger.info(f"    Prompts File: {img_info['saved_prompts_path']}")
                    logger.info(f"    CLIP Score: {img_info['clip_score']:.3f}")
                    logger.info("")
            
            # Wandb ë¡œê¹…
            if hasattr(self, 'wandb_logger') and self.wandb_logger:
                self.wandb_logger.log_validation_results(val_results)
                
                # ì´ë¯¸ì§€ë„ wandbì— ì—…ë¡œë“œ (ê°€ëŠ¥í•œ ê²½ìš°)
                if save_images and val_results.get('saved_images'):
                    try:
                        from PIL import Image
                        images_for_wandb = []
                        captions_for_wandb = []
                        
                        for img_info in val_results['saved_images'][:5]:  # ì²˜ìŒ 5ê°œë§Œ
                            try:
                                img_path = img_info['image_path']
                                if os.path.exists(img_path):
                                    pil_image = Image.open(img_path)
                                    images_for_wandb.append(pil_image)
                                    caption = f"Iter {iteration}: {img_info['prompt'][:30]}... (CLIP: {img_info['clip_score']:.3f})"
                                    captions_for_wandb.append(caption)
                            except Exception as e:
                                logger.warning(f"âš ï¸ Failed to load image for wandb: {e}")
                        
                        if images_for_wandb:
                            self.wandb_logger.log_images(images_for_wandb, captions_for_wandb, step=iteration)
                            logger.info(f"ğŸ“ˆ Uploaded {len(images_for_wandb)} images to wandb")
                            
                    except Exception as e:
                        logger.warning(f"âš ï¸ Failed to upload images to wandb: {e}")
                
        except Exception as e:
            logger.error(f"âŒ Validation failed: {e}")
    
    def _save_checkpoint(self, iteration: int):
        """ì²´í¬í¬ì¸íŠ¸ ì €ì¥"""
        if self.grpo_trainer is None:
            logger.warning("âš ï¸ GRPO trainer not initialized, skipping checkpoint save")
            return
            
        try:
            checkpoint_path = f"{self.config['output_settings']['output_dir']}/checkpoint_iter_{iteration}.pt"
            self.grpo_trainer.save_checkpoint(checkpoint_path)
            logger.info(f"ğŸ’¾ Checkpoint saved: {checkpoint_path}")
        except Exception as e:
            logger.error(f"âŒ Failed to save checkpoint: {e}")
    
    def _save_best_model(self, iteration: int):
        """ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ì €ì¥"""
        if self.grpo_trainer is None:
            logger.warning("âš ï¸ GRPO trainer not initialized, skipping best model save")
            return
            
        try:
            best_model_path = f"{self.config['output_settings']['output_dir']}/best_model.pt"
            self.grpo_trainer.save_checkpoint(best_model_path)
            logger.info(f"ğŸ† Best model saved: {best_model_path}")
        except Exception as e:
            logger.error(f"âŒ Failed to save best model: {e}")
    
    def _save_final_results(self):
        """ìµœì¢… ê²°ê³¼ ì €ì¥"""
        try:
            results_path = f"{self.config['output_settings']['output_dir']}/final_results.json"
            
            # í•™ìŠµ í†µê³„ ìˆ˜ì§‘
            final_stats = self.training_stats.copy()
            
            # GRPO í†µê³„ ì¶”ê°€ (ìˆë‹¤ë©´)
            if self.grpo_trainer is not None and hasattr(self.grpo_trainer, 'get_training_stats'):
                grpo_stats = self.grpo_trainer.get_training_stats()
                final_stats.update(grpo_stats)
            
            # ê²°ê³¼ ì €ì¥
            with open(results_path, 'w', encoding='utf-8') as f:
                json.dump(final_stats, f, indent=2, ensure_ascii=False)
            
            logger.info(f"ğŸ“‹ Final results saved: {results_path}")
            
        except Exception as e:
            logger.error(f"âŒ Failed to save final results: {e}")


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸš€ VLM GRPO System Starting...")
    print("=" * 50)
    
    try:
        # ì‹œìŠ¤í…œ ì´ˆê¸°í™”
        system = VLMGRPOSystem()
        
        # ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™”
        system.initialize_components()
        
        # í•™ìŠµ ì‹¤í–‰
        system.run_training()
        
        print("\nâœ… Training completed successfully!")
        
    except KeyboardInterrupt:
        print("\nâš ï¸ Training interrupted by user")
    except Exception as e:
        print(f"\nâŒ Training failed: {e}")
        raise


if __name__ == "__main__":
    main() 