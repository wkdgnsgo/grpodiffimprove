#!/usr/bin/env python3
"""
ê°œì„ ëœ ìˆ˜ì¹˜ì  ì•ˆì •ì„± ë° ë¡œê·¸ ì œì–´ í…ŒìŠ¤íŠ¸

ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” ë‹¤ìŒ ê°œì„ ì‚¬í•­ë“¤ì„ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤:
1. Score NaN/Inf ë¬¸ì œ í•´ê²° (ì˜ˆë°©ì  í´ë¦¬í•‘)
2. ë¶ˆí•„ìš”í•œ ìƒì„¸ ë¡œê·¸ ì œê±° (ìš”ì•½ í˜•íƒœë¡œ ë³€ê²½)
3. ì¡°ê±´ë¶€ NaN/Inf ê²½ê³  ë¡œê·¸
4. EasyR1 ìŠ¤íƒ€ì¼ ì•ˆì •ì„± ê¸°ë²• ê²€ì¦
"""

import torch
import logging
from qwen import QWENModel, QWENGRPOConfig

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

def test_quiet_mode():
    """ì¡°ìš©í•œ ëª¨ë“œ (NaN/Inf ê²½ê³  ì—†ìŒ, ê°„ë‹¨í•œ ë¡œê·¸)"""
    
    logger.info("ğŸ”‡ ì¡°ìš©í•œ ëª¨ë“œ í…ŒìŠ¤íŠ¸ ì‹œì‘")
    
    # ì¡°ìš©í•œ ì„¤ì •
    grpo_config = QWENGRPOConfig(
        learning_rate=1e-4,
        batch_size=1,
        num_rollouts=1,
        max_new_tokens=10,
        
        # EasyR1 ì•ˆì •ì„± ê¸°ë²• í™œì„±í™”
        use_adaptive_grad_clip=True,
        use_grad_centralization=True,
        use_grad_normalization=True,
        use_stochastic_rounding=True,
        logits_clip_range=20.0,
        
        # ë¡œê·¸ ì œì–´ - ì¡°ìš©í•œ ëª¨ë“œ
        verbose_logging=False,
        log_nan_inf_warnings=False  # NaN/Inf ê²½ê³  ë¹„í™œì„±í™”
    )
    
    logger.info("ğŸ”§ QWEN ëª¨ë¸ ì´ˆê¸°í™” (ì¡°ìš©í•œ ëª¨ë“œ)...")
    model = QWENModel(
        device="cuda" if torch.cuda.is_available() else "cpu",
        grpo_config=grpo_config
    )
    
    logger.info("âœ… ëª¨ë¸ ì´ˆê¸°í™” ì™„ë£Œ - ìƒì„¸ ë¡œê·¸ ì—†ì´ ìš”ì•½ë§Œ ì¶œë ¥ë¨")
    
    # í”„ë¡¬í”„íŠ¸ í–¥ìƒ í…ŒìŠ¤íŠ¸
    test_prompts = ["cat", "dog", "flower"]
    
    logger.info("ğŸ§ª í”„ë¡¬í”„íŠ¸ í–¥ìƒ í…ŒìŠ¤íŠ¸ (ì¡°ìš©í•œ ëª¨ë“œ)")
    for prompt in test_prompts:
        try:
            result = model.enhance_prompt(prompt)
            logger.info(f"  âœ… '{prompt}' -> '{result['enhanced_prompt'][:30]}...'")
        except Exception as e:
            logger.error(f"  âŒ '{prompt}' ì‹¤íŒ¨: {e}")
    
    logger.info("âœ… ì¡°ìš©í•œ ëª¨ë“œ í…ŒìŠ¤íŠ¸ ì™„ë£Œ - NaN/Inf ê²½ê³  ì—†ìŒ")
    
    return model

def test_verbose_mode():
    """ìƒì„¸ ëª¨ë“œ (NaN/Inf ê²½ê³  í¬í•¨, ìƒì„¸ ë¡œê·¸)"""
    
    logger.info("\nğŸ”Š ìƒì„¸ ëª¨ë“œ í…ŒìŠ¤íŠ¸ ì‹œì‘")
    
    # ìƒì„¸ ì„¤ì •
    grpo_config = QWENGRPOConfig(
        learning_rate=1e-4,
        batch_size=1,
        num_rollouts=1,
        max_new_tokens=10,
        
        # EasyR1 ì•ˆì •ì„± ê¸°ë²• í™œì„±í™”
        use_adaptive_grad_clip=True,
        use_grad_centralization=True,
        use_grad_normalization=True,
        use_stochastic_rounding=True,
        logits_clip_range=20.0,
        
        # ë¡œê·¸ ì œì–´ - ìƒì„¸ ëª¨ë“œ
        verbose_logging=True,
        log_nan_inf_warnings=True  # NaN/Inf ê²½ê³  í™œì„±í™”
    )
    
    logger.info("ğŸ”§ QWEN ëª¨ë¸ ì´ˆê¸°í™” (ìƒì„¸ ëª¨ë“œ)...")
    model = QWENModel(
        device="cuda" if torch.cuda.is_available() else "cpu",
        grpo_config=grpo_config
    )
    
    logger.info("âœ… ëª¨ë¸ ì´ˆê¸°í™” ì™„ë£Œ - í•„ìš”ì‹œ ìƒì„¸ ë¡œê·¸ ì¶œë ¥")
    
    # ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸ë§Œ ìˆ˜í–‰ (ë©”ëª¨ë¦¬ ì ˆì•½)
    test_prompt = "beautiful sunset"
    
    logger.info("ğŸ§ª í”„ë¡¬í”„íŠ¸ í–¥ìƒ í…ŒìŠ¤íŠ¸ (ìƒì„¸ ëª¨ë“œ)")
    try:
        result = model.enhance_prompt(test_prompt)
        logger.info(f"  âœ… '{test_prompt}' -> '{result['enhanced_prompt'][:30]}...'")
    except Exception as e:
        logger.error(f"  âŒ '{test_prompt}' ì‹¤íŒ¨: {e}")
    
    logger.info("âœ… ìƒì„¸ ëª¨ë“œ í…ŒìŠ¤íŠ¸ ì™„ë£Œ - í•„ìš”ì‹œ ìƒì„¸ ì •ë³´ ì¶œë ¥ë¨")
    
    return model

def test_stability_improvements():
    """ì•ˆì •ì„± ê°œì„ ì‚¬í•­ í…ŒìŠ¤íŠ¸"""
    
    logger.info("\nğŸ›¡ï¸ ì•ˆì •ì„± ê°œì„ ì‚¬í•­ í…ŒìŠ¤íŠ¸")
    
    # ê¸°ë³¸ ì•ˆì •ì„± ì„¤ì •
    grpo_config = QWENGRPOConfig(
        learning_rate=1e-4,
        batch_size=1,
        max_new_tokens=10,
        
        # EasyR1 ì•ˆì •ì„± ê¸°ë²• ëª¨ë‘ í™œì„±í™”
        use_adaptive_grad_clip=True,
        grad_clip_ema_beta=0.99,
        grad_clip_coef=1.5,
        use_grad_centralization=True,
        use_grad_normalization=True,
        grad_norm_alpha=0.5,
        use_stochastic_rounding=True,
        logits_clip_range=20.0,  # ë³´ìˆ˜ì ì¸ í´ë¦¬í•‘
        stable_log_prob_min=-50.0,
        
        # ì¡°ìš©í•œ ëª¨ë“œ
        verbose_logging=False,
        log_nan_inf_warnings=False
    )
    
    model = QWENModel(
        device="cuda" if torch.cuda.is_available() else "cpu",
        grpo_config=grpo_config
    )
    
    logger.info("ğŸ” ì•ˆì •ì„± ê¸°ë²• í™•ì¸:")
    logger.info(f"  - ì ì‘ì  ê·¸ë˜ë””ì–¸íŠ¸ í´ë¦¬í•‘: {model.grpo_config.use_adaptive_grad_clip}")
    logger.info(f"  - ê·¸ë˜ë””ì–¸íŠ¸ ì¤‘ì•™í™”: {model.grpo_config.use_grad_centralization}")
    logger.info(f"  - ê·¸ë˜ë””ì–¸íŠ¸ ì •ê·œí™”: {model.grpo_config.use_grad_normalization}")
    logger.info(f"  - í™•ë¥ ì  ë°˜ì˜¬ë¦¼: {model.grpo_config.use_stochastic_rounding}")
    logger.info(f"  - Logits í´ë¦¬í•‘ ë²”ìœ„: Â±{model.grpo_config.logits_clip_range}")
    logger.info(f"  - NaN/Inf ê²½ê³ : {model.grpo_config.log_nan_inf_warnings}")
    
    # ë¡œê·¸ í™•ë¥  ê³„ì‚° ì•ˆì •ì„± í…ŒìŠ¤íŠ¸
    logger.info("ğŸ§ª ë¡œê·¸ í™•ë¥  ê³„ì‚° ì•ˆì •ì„± í…ŒìŠ¤íŠ¸")
    
    test_cases = [
        ("cat", "cat, high quality photography"),
        ("dog", "dog, professional portrait"),
    ]
    
    for user_prompt, enhanced_prompt in test_cases:
        try:
            # í˜„ì¬ ëª¨ë¸ ë¡œê·¸ í™•ë¥ 
            current_log_prob = model.calculate_log_prob_for_grpo(user_prompt, enhanced_prompt)
            
            # ì•ˆì •ì„± ê²€ì¦
            if torch.isnan(current_log_prob) or torch.isinf(current_log_prob):
                logger.error(f"  âŒ '{user_prompt}': ì—¬ì „íˆ NaN/Inf ë°œìƒ!")
            else:
                logger.info(f"  âœ… '{user_prompt}': ì•ˆì •ì  ({current_log_prob:.4f})")
                
        except Exception as e:
            logger.error(f"  âŒ '{user_prompt}': ì˜¤ë¥˜ ë°œìƒ - {e}")
    
    logger.info("âœ… ì•ˆì •ì„± ê°œì„ ì‚¬í•­ í…ŒìŠ¤íŠ¸ ì™„ë£Œ")
    
    return model

def compare_log_levels():
    """ë¡œê·¸ ë ˆë²¨ ë¹„êµ"""
    
    logger.info("\nğŸ“Š ë¡œê·¸ ë ˆë²¨ ë¹„êµ í…ŒìŠ¤íŠ¸")
    
    logger.info("ğŸ”‡ ì¡°ìš©í•œ ëª¨ë“œ:")
    logger.info("  - íŒŒë¼ë¯¸í„° ì •ë³´: ìš”ì•½ë§Œ ì¶œë ¥")
    logger.info("  - NaN/Inf ê²½ê³ : ë¹„í™œì„±í™”")
    logger.info("  - ë””ë°”ì´ìŠ¤ ì •ë³´: ìµœì†Œí•œë§Œ ì¶œë ¥")
    
    logger.info("ğŸ”Š ìƒì„¸ ëª¨ë“œ:")
    logger.info("  - íŒŒë¼ë¯¸í„° ì •ë³´: í•„ìš”ì‹œ ìƒì„¸ ì¶œë ¥")
    logger.info("  - NaN/Inf ê²½ê³ : í™œì„±í™”")
    logger.info("  - ë””ë°”ì´ìŠ¤ ì •ë³´: ìƒì„¸ ì¶œë ¥")
    
    logger.info("âœ… ë¡œê·¸ ë ˆë²¨ ë¹„êµ ì™„ë£Œ")

def main():
    """ë©”ì¸ í…ŒìŠ¤íŠ¸ í•¨ìˆ˜"""
    
    logger.info("ğŸš€ ê°œì„ ëœ ìˆ˜ì¹˜ì  ì•ˆì •ì„± ë° ë¡œê·¸ ì œì–´ í…ŒìŠ¤íŠ¸ ì‹œì‘")
    
    try:
        # 1. ì¡°ìš©í•œ ëª¨ë“œ í…ŒìŠ¤íŠ¸
        quiet_model = test_quiet_mode()
        
        # ë©”ëª¨ë¦¬ ì •ë¦¬
        del quiet_model
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
        
        # 2. ìƒì„¸ ëª¨ë“œ í…ŒìŠ¤íŠ¸ (ë©”ëª¨ë¦¬ ì ˆì•½ì„ ìœ„í•´ ê°„ë‹¨íˆ)
        verbose_model = test_verbose_mode()
        
        # ë©”ëª¨ë¦¬ ì •ë¦¬
        del verbose_model
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
        
        # 3. ì•ˆì •ì„± ê°œì„ ì‚¬í•­ í…ŒìŠ¤íŠ¸
        stability_model = test_stability_improvements()
        
        # 4. ë¡œê·¸ ë ˆë²¨ ë¹„êµ
        compare_log_levels()
        
        print("\n" + "="*80)
        print("ğŸ‰ ëª¨ë“  í…ŒìŠ¤íŠ¸ ì„±ê³µ!")
        print("="*80)
        print("âœ… Score NaN/Inf ë¬¸ì œ í•´ê²°ë¨")
        print("âœ… ë¶ˆí•„ìš”í•œ ìƒì„¸ ë¡œê·¸ ì œê±°ë¨")
        print("âœ… ì¡°ê±´ë¶€ ê²½ê³  ë¡œê·¸ êµ¬í˜„ë¨")
        print("âœ… EasyR1 ìŠ¤íƒ€ì¼ ì•ˆì •ì„± ê¸°ë²• ì ìš©ë¨")
        print("="*80)
        
    except Exception as e:
        logger.error(f"âŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main() 