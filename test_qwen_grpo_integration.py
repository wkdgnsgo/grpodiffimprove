#!/usr/bin/env python3
"""
QWEN GRPO í†µí•© ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸
ê¸°ë³¸ ê¸°ëŠ¥ë“¤ì´ ì œëŒ€ë¡œ ì‘ë™í•˜ëŠ”ì§€ í™•ì¸
"""

import torch
import logging
from qwen import QWENModel, QWENGRPOConfig

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def test_qwen_grpo_integration():
    """QWEN GRPO í†µí•© ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸"""
    logger.info("ğŸ§ª QWEN GRPO í†µí•© ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ì‹œì‘")
    
    # í…ŒìŠ¤íŠ¸ìš© ì„¤ì •
    config = QWENGRPOConfig(
        learning_rate=1e-6,
        batch_size=2,
        num_rollouts=2,
        num_enhancement_candidates=3,  # 3ê°œ í›„ë³´ë¡œ í…ŒìŠ¤íŠ¸
        save_images=False  # ì´ë¯¸ì§€ ì €ì¥ ë¹„í™œì„±í™”
    )
    
    try:
        # 1. QWEN ëª¨ë¸ ë¡œë“œ (GRPO í†µí•©)
        logger.info("ğŸ§  QWEN + GRPO ëª¨ë¸ ë¡œë”©...")
        qwen_model = QWENModel(
            model_name="Qwen/Qwen2-VL-7B-Instruct",
            device="cuda:0" if torch.cuda.is_available() else "cpu",
            temperature=0.7,
            grpo_config=config
        )
        logger.info("âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
        
        # 2. ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ í–¥ìƒ í…ŒìŠ¤íŠ¸
        test_prompt = "a beautiful sunset over mountains"
        logger.info(f"\nğŸ“ í…ŒìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸: '{test_prompt}'")
        
        # ê¸°ë³¸ enhance_prompt í…ŒìŠ¤íŠ¸
        logger.info("ğŸ” ê¸°ë³¸ enhance_prompt í…ŒìŠ¤íŠ¸...")
        basic_result = qwen_model.enhance_prompt(test_prompt)
        logger.info(f"  ì›ë³¸: {test_prompt}")
        logger.info(f"  í–¥ìƒ: {basic_result['enhanced_prompt']}")
        
        # 3. í›„ë³´ ìƒì„± í…ŒìŠ¤íŠ¸
        logger.info("\nğŸ¯ í›„ë³´ ìƒì„± í…ŒìŠ¤íŠ¸...")
        candidates = qwen_model.generate_enhancement_candidates(test_prompt)
        logger.info(f"  ìƒì„±ëœ í›„ë³´ ìˆ˜: {len(candidates)}")
        for i, candidate in enumerate(candidates):
            logger.info(f"  í›„ë³´ {i}: {candidate}")
        
        # 4. GRPO ì•¡ì…˜ ì„ íƒ í…ŒìŠ¤íŠ¸
        logger.info("\nğŸ² GRPO ì•¡ì…˜ ì„ íƒ í…ŒìŠ¤íŠ¸...")
        action, log_prob, action_candidates = qwen_model.get_grpo_action_and_log_prob(test_prompt)
        logger.info(f"  ì„ íƒëœ ì•¡ì…˜: {action}")
        logger.info(f"  ë¡œê·¸ í™•ë¥ : {log_prob:.4f}")
        logger.info(f"  ì„ íƒëœ í”„ë¡¬í”„íŠ¸: {action_candidates[action]}")
        
        # 5. ìƒíƒœ í‘œí˜„ í…ŒìŠ¤íŠ¸
        logger.info("\nğŸ§® ìƒíƒœ í‘œí˜„ í…ŒìŠ¤íŠ¸...")
        state_repr = qwen_model.get_grpo_state_representation(test_prompt)
        logger.info(f"  ìƒíƒœ í‘œí˜„ í¬ê¸°: {state_repr.shape}")
        logger.info(f"  ìƒíƒœ í‘œí˜„ íƒ€ì…: {state_repr.dtype}")
        
        # 6. ì°¸ì¡° ì •ì±… í…ŒìŠ¤íŠ¸
        logger.info("\nğŸ“Š ì°¸ì¡° ì •ì±… í…ŒìŠ¤íŠ¸...")
        ref_log_prob = qwen_model.get_ref_policy_log_prob(test_prompt, action)
        logger.info(f"  ì°¸ì¡° ì •ì±… ë¡œê·¸ í™•ë¥ : {ref_log_prob:.4f}")
        
        # 7. ê°„ë‹¨í•œ ê²½í—˜ ë°ì´í„°ë¡œ ì—…ë°ì´íŠ¸ í…ŒìŠ¤íŠ¸
        logger.info("\nğŸ¯ GRPO ì—…ë°ì´íŠ¸ í…ŒìŠ¤íŠ¸...")
        fake_experiences = [
            {
                'user_prompt': test_prompt,
                'action': action,
                'log_prob': log_prob,
                'reward': 0.5
            },
            {
                'user_prompt': test_prompt,
                'action': (action + 1) % len(action_candidates),
                'log_prob': log_prob * 0.9,
                'reward': 0.3
            }
        ]
        
        metrics = qwen_model.update_grpo_policy(fake_experiences)
        logger.info("  ì—…ë°ì´íŠ¸ ë©”íŠ¸ë¦­:")
        for key, value in metrics.items():
            logger.info(f"    {key}: {value:.4f}")
        
        logger.info("\nâœ… ëª¨ë“  í…ŒìŠ¤íŠ¸ í†µê³¼!")
        return True
        
    except Exception as e:
        logger.error(f"âŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_prompt_quality():
    """í”„ë¡¬í”„íŠ¸ í’ˆì§ˆ ë¹„êµ í…ŒìŠ¤íŠ¸"""
    logger.info("\nğŸ” í”„ë¡¬í”„íŠ¸ í’ˆì§ˆ ë¹„êµ í…ŒìŠ¤íŠ¸")
    
    config = QWENGRPOConfig(num_enhancement_candidates=5, save_images=False)
    
    try:
        qwen_model = QWENModel(
            device="cuda:0" if torch.cuda.is_available() else "cpu",
            grpo_config=config
        )
        
        test_prompts = [
            "a cat",
            "beautiful landscape",
            "futuristic city",
            "abstract art"
        ]
        
        for prompt in test_prompts:
            logger.info(f"\nğŸ“ í…ŒìŠ¤íŠ¸: '{prompt}'")
            
            # ê¸°ë³¸ í–¥ìƒ
            basic = qwen_model.enhance_prompt(prompt)
            logger.info(f"  ê¸°ë³¸: {basic['enhanced_prompt']}")
            
            # GRPO í›„ë³´ë“¤
            candidates = qwen_model.generate_enhancement_candidates(prompt)
            logger.info("  GRPO í›„ë³´ë“¤:")
            for i, candidate in enumerate(candidates):
                logger.info(f"    {i}: {candidate}")
            
            # GRPO ì„ íƒ
            action, _, _ = qwen_model.get_grpo_action_and_log_prob(prompt)
            logger.info(f"  GRPO ì„ íƒ (ì•¡ì…˜ {action}): {candidates[action]}")
        
        logger.info("\nâœ… í’ˆì§ˆ ë¹„êµ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
        return True
        
    except Exception as e:
        logger.error(f"âŒ í’ˆì§ˆ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        return False

if __name__ == "__main__":
    logger.info("ğŸš€ QWEN GRPO í†µí•© í…ŒìŠ¤íŠ¸ ì‹œì‘")
    logger.info("=" * 60)
    
    # ê¸°ë³¸ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸
    success1 = test_qwen_grpo_integration()
    
    # í’ˆì§ˆ ë¹„êµ í…ŒìŠ¤íŠ¸
    success2 = test_prompt_quality()
    
    if success1 and success2:
        logger.info("\nğŸ‰ ëª¨ë“  í…ŒìŠ¤íŠ¸ê°€ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
    else:
        logger.error("\nâŒ ì¼ë¶€ í…ŒìŠ¤íŠ¸ê°€ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.") 