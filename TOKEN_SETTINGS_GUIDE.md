# í† í° ì„¤ì • í†µì¼ ê°€ì´ë“œ

## ğŸ“‹ ê°œìš”

VLM GRPO ì‹œìŠ¤í…œì—ì„œ í† í° ê´€ë ¨ ì„¤ì •ì„ í†µì¼í•˜ì—¬ ì¼ê´€ì„±ê³¼ ìœ ì§€ë³´ìˆ˜ì„±ì„ ê°œì„ í–ˆìŠµë‹ˆë‹¤.

## ğŸ”§ ë³€ê²½ì‚¬í•­

### âœ… í†µí•©ëœ í† í° ì„¤ì •

ê¸°ì¡´ì— ì—¬ëŸ¬ ê³³ì— ë¶„ì‚°ë˜ì–´ ìˆë˜ í† í° ì„¤ì •ì„ `config/default_config.json`ì˜ `token_settings` ì„¹ì…˜ìœ¼ë¡œ í†µí•©í–ˆìŠµë‹ˆë‹¤.

```json
{
  "token_settings": {
    "_comment": "í† í° ê´€ë ¨ í†µí•© ì„¤ì •",
    "max_new_tokens": 25,
    "max_prompt_length": 77,
    "max_sequence_length": 102,
    "_description": "max_sequence_length = max_prompt_length + max_new_tokens"
  }
}
```

### ğŸ“Š ê° ì„¤ì •ì˜ ì˜ë¯¸

| ì„¤ì •                  | ê°’  | ìš©ë„        | ì„¤ëª…                                  |
| --------------------- | --- | ----------- | ------------------------------------- |
| `max_new_tokens`      | 25  | GRPO í•™ìŠµ   | ì •ì±… ë„¤íŠ¸ì›Œí¬ê°€ ìƒì„±í•  ìƒˆë¡œìš´ í† í° ìˆ˜ |
| `max_prompt_length`   | 77  | ì…ë ¥ ê²€ì¦   | CLIP ëª¨ë¸ì˜ 77í† í° ì œí•œì„ ì¤€ìˆ˜        |
| `max_sequence_length` | 102 | ë©”ëª¨ë¦¬ í• ë‹¹ | ì „ì²´ ì‹œí€€ìŠ¤ ê¸¸ì´ (77 + 25)            |

## ğŸ—‚ï¸ ê¸°ì¡´ ì„¤ì • ì œê±°

### âŒ ì œê±°ëœ ì¤‘ë³µ ì„¤ì •ë“¤

1. **`training_settings.vlm_policy_settings`** â†’ `token_settings`ë¡œ í†µí•©
2. **`generation_settings.vlm_generation.max_new_tokens`** â†’ `token_settings.max_new_tokens` ì°¸ì¡°
3. **GRPO trainerì˜ í•˜ë“œì½”ë”©ëœ ê°’ë“¤** â†’ Configì—ì„œ ë™ì  ë¡œë“œ

### âœ… ê°„ì†Œí™”ëœ êµ¬ì¡°

```json
{
  "generation_settings": {
    "vlm_generation": {
      "_comment": "VLM ìƒì„± íŒŒë¼ë¯¸í„° - token_settingsì—ì„œ max_new_tokens ì°¸ì¡°",
      "temperature": 0.8,
      "top_p": 0.9,
      "do_sample": true,
      "use_cache": true
    }
  }
}
```

## ğŸ”„ ì½”ë“œ ë³€ê²½ì‚¬í•­

### 1. **GRPO Trainer (`training/grpo_trainer.py`)**

```python
# ê¸°ì¡´ (í•˜ë“œì½”ë”©)
max_new_tokens: int = 25
max_sequence_length: int = 100

# ë³€ê²½ í›„ (Config ê¸°ë°˜)
max_new_tokens: int = 25      # Configì—ì„œ ë¡œë“œë¨
max_prompt_length: int = 77   # CLIP ì œí•œ
max_sequence_length: int = 102 # prompt + new_tokens
```

### 2. **Main Trainer (`integration/main_trainer.py`)**

```python
# ê¸°ì¡´ (ë¶„ì‚°ëœ ì„¤ì • ì°¸ì¡°)
max_new_tokens=self.config['generation_settings']['vlm_generation']['max_new_tokens']

# ë³€ê²½ í›„ (í†µí•©ëœ ì„¤ì • ì°¸ì¡°)
max_new_tokens=self.config['token_settings']['max_new_tokens']
```

### 3. **VLM Wrapper (`models/vlm_wrapper.py`)**

```python
# ê¸°ì¡´ (í•˜ë“œì½”ë”©)
if max_new_tokens is None:
    max_new_tokens = 20

# ë³€ê²½ í›„ (Config ê¸°ë°˜)
if max_new_tokens is None:
    config = self._load_config()
    max_new_tokens = config.get('token_settings', {}).get('max_new_tokens', 20)
```

## ğŸ“ˆ ì¥ì 

### 1. **ì¼ê´€ì„± ë³´ì¥**

- ëª¨ë“  ì»´í¬ë„ŒíŠ¸ê°€ ë™ì¼í•œ í† í° ì„¤ì •ì„ ì‚¬ìš©
- ì„¤ì • ë³€ê²½ ì‹œ í•œ ê³³ì—ì„œë§Œ ìˆ˜ì •í•˜ë©´ ë¨

### 2. **ìœ ì§€ë³´ìˆ˜ì„± í–¥ìƒ**

- ì¤‘ë³µ ì„¤ì • ì œê±°ë¡œ í˜¼ë€ ë°©ì§€
- ëª…í™•í•œ ì„¤ì • êµ¬ì¡°ë¡œ ì´í•´ë„ í–¥ìƒ

### 3. **í™•ì¥ì„± ê°œì„ **

- ìƒˆë¡œìš´ í† í° ê´€ë ¨ ì„¤ì • ì¶”ê°€ ì‹œ ì¼ê´€ëœ ìœ„ì¹˜
- ì„¤ì • ê²€ì¦ ë° ê³„ì‚° ë¡œì§ í†µí•© ê°€ëŠ¥

## ğŸ¯ ì‚¬ìš© ë°©ë²•

### Configì—ì„œ í† í° ì„¤ì • ì ‘ê·¼

```python
# Python ì½”ë“œì—ì„œ
config = load_config()
max_new_tokens = config['token_settings']['max_new_tokens']
max_prompt_length = config['token_settings']['max_prompt_length']
max_sequence_length = config['token_settings']['max_sequence_length']
```

### ì„¤ì • ë³€ê²½

```json
{
  "token_settings": {
    "max_new_tokens": 30, // ë” ê¸´ ìƒì„±ì„ ì›í•  ë•Œ
    "max_prompt_length": 77, // CLIP ì œí•œ (ê³ ì •)
    "max_sequence_length": 107 // 77 + 30
  }
}
```

## âš ï¸ ì£¼ì˜ì‚¬í•­

### 1. **CLIP ì œí•œ**

- `max_prompt_length`ëŠ” 77ë¡œ ê³ ì • (CLIP ëª¨ë¸ ì œí•œ)
- ì´ ê°’ì„ ë³€ê²½í•˜ë©´ CLIP ë³´ìƒ ê³„ì‚°ì— ë¬¸ì œ ë°œìƒ ê°€ëŠ¥

### 2. **ë©”ëª¨ë¦¬ ê³ ë ¤ì‚¬í•­**

- `max_sequence_length` ì¦ê°€ ì‹œ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¦ê°€
- GPU ë©”ëª¨ë¦¬ í•œê³„ë¥¼ ê³ ë ¤í•˜ì—¬ ì„¤ì •

### 3. **í•™ìŠµ íš¨ìœ¨ì„±**

- `max_new_tokens`ê°€ ë„ˆë¬´ í¬ë©´ í•™ìŠµì´ ë¶ˆì•ˆì •í•´ì§ˆ ìˆ˜ ìˆìŒ
- 25-30 í† í°ì´ ì ì ˆí•œ ë²”ìœ„

## ğŸ” ê²€ì¦ ë°©ë²•

### ì„¤ì • ì¼ê´€ì„± í™•ì¸

```python
# ìë™ ê²€ì¦ ìŠ¤í¬ë¦½íŠ¸
def validate_token_settings(config):
    token_settings = config['token_settings']

    max_new = token_settings['max_new_tokens']
    max_prompt = token_settings['max_prompt_length']
    max_seq = token_settings['max_sequence_length']

    assert max_seq == max_prompt + max_new, f"Sequence length mismatch: {max_prompt} + {max_new} â‰  {max_seq}"
    assert max_prompt == 77, f"CLIP constraint violated: {max_prompt} â‰  77"

    print("âœ… Token settings validation passed!")
```

## ğŸ‰ ê²°ë¡ 

í† í° ì„¤ì • í†µì¼ì„ í†µí•´:

- âœ… **ì¼ê´€ì„±**: ëª¨ë“  ì»´í¬ë„ŒíŠ¸ê°€ ë™ì¼í•œ ì„¤ì • ì‚¬ìš©
- âœ… **ëª…í™•ì„±**: ê° ì„¤ì •ì˜ ì—­í• ê³¼ ì œì•½ì‚¬í•­ ëª…í™•í™”
- âœ… **ìœ ì§€ë³´ìˆ˜ì„±**: ì¤‘ë³µ ì œê±°ë¡œ ê´€ë¦¬ í¸ì˜ì„± í–¥ìƒ
- âœ… **í™•ì¥ì„±**: ìƒˆë¡œìš´ í† í° ê´€ë ¨ ê¸°ëŠ¥ ì¶”ê°€ ì‹œ ì¼ê´€ëœ êµ¬ì¡°

ì´ì œ í† í° ê´€ë ¨ ì„¤ì •ì„ ìˆ˜ì •í•  ë•Œ `config/default_config.json`ì˜ `token_settings` ì„¹ì…˜ë§Œ ìˆ˜ì •í•˜ë©´ ë©ë‹ˆë‹¤! ğŸš€
