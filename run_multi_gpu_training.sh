#!/bin/bash

# Multi-GPU GRPO Training Script
# ===============================
# GPU 1, 2, 3ë²ˆì„ ì‚¬ìš©í•˜ì—¬ QWEN ëª¨ë¸ì„ GRPOë¡œ í•™ìŠµí•©ë‹ˆë‹¤.

echo "ğŸš€ Starting Multi-GPU GRPO Training"
echo "=================================="

# GPU í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
export CUDA_VISIBLE_DEVICES=1,2,3
export CUDA_LAUNCH_BLOCKING=0
export TORCH_CUDA_ARCH_LIST="8.0;8.6;8.9;9.0"
export PYTORCH_CUDA_ALLOC_CONF="max_split_size_mb:512"
export NCCL_DEBUG=INFO
export NCCL_IB_DISABLE=1

echo "ğŸ”§ GPU Environment Variables:"
echo "  CUDA_VISIBLE_DEVICES: $CUDA_VISIBLE_DEVICES"
echo "  PYTORCH_CUDA_ALLOC_CONF: $PYTORCH_CUDA_ALLOC_CONF"

# GPU ìƒíƒœ í™•ì¸
echo ""
echo "ğŸ“± GPU Status Check:"
nvidia-smi --query-gpu=index,name,memory.used,memory.total,utilization.gpu --format=csv,noheader,nounits | grep -E "^[1-3],"

echo ""
echo "ğŸ¯ Model GPU Assignment:"
echo "  GPU 1 (cuda:0): QWEN VL Model (Policy Network)"
echo "  GPU 2 (cuda:1): Stable Diffusion 3 (Environment)"  
echo "  GPU 3 (cuda:2): CLIP Model (Reward Calculator)"

echo ""
echo "âš¡ Starting GRPO Training..."
echo "=================================="

# Python í•™ìŠµ ì‹¤í–‰
python train_grpo.py

# í•™ìŠµ ì™„ë£Œ í›„ GPU ë©”ëª¨ë¦¬ ìƒíƒœ í™•ì¸
echo ""
echo "ğŸ“Š Post-Training GPU Status:"
nvidia-smi --query-gpu=index,name,memory.used,memory.total,utilization.gpu --format=csv,noheader,nounits | grep -E "^[1-3],"

echo ""
echo "ğŸ‰ Multi-GPU GRPO Training Completed!" 