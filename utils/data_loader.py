"""
Data Loader Utilities
====================

VLM GRPO í•™ìŠµì„ ìœ„í•œ ë°ì´í„° ë¡œë”© ë° ê´€ë¦¬ ìœ í‹¸ë¦¬í‹°ì…ë‹ˆë‹¤.

ì£¼ìš” ê¸°ëŠ¥:
1. í•™ìŠµ/ê²€ì¦ í”„ë¡¬í”„íŠ¸ ë¡œë”©
2. ë°ì´í„° ì „ì²˜ë¦¬
3. ë°°ì¹˜ ìƒì„±
4. ë°ì´í„° ì¦ê°•

Author: AI Assistant  
Date: 2025-01-22
"""

import json
import random
from typing import List, Dict, Optional, Tuple, Any
import logging
from pathlib import Path

logger = logging.getLogger(__name__)

class PromptDataLoader:
    """
    í”„ë¡¬í”„íŠ¸ ë°ì´í„° ë¡œë”© ë° ê´€ë¦¬ í´ë˜ìŠ¤
    
    ì´ í´ë˜ìŠ¤ëŠ”:
    1. JSONL í˜•ì‹ì˜ í”„ë¡¬í”„íŠ¸ ë°ì´í„° ë¡œë”©
    2. ì¹´í…Œê³ ë¦¬ ë° ë‚œì´ë„ë³„ ë¶„ë¥˜
    3. ë°°ì¹˜ ìƒì„± ë° ì…”í”Œë§
    4. ë°ì´í„° í†µê³„ ì œê³µ
    """
    
    def __init__(self, 
                 train_data_path: str = "train_prompts.jsonl",
                 val_data_path: str = "val_prompts.jsonl",
                 batch_shuffle: bool = True):
        """
        Data Loader ì´ˆê¸°í™”
        
        Args:
            train_data_path (str): í•™ìŠµ ë°ì´í„° ê²½ë¡œ
            val_data_path (str): ê²€ì¦ ë°ì´í„° ê²½ë¡œ
            batch_shuffle (bool): ë°°ì¹˜ ìƒì„± ì‹œ ì…”í”Œ ì—¬ë¶€
        """
        self.train_data_path = train_data_path
        self.val_data_path = val_data_path
        self.batch_shuffle = batch_shuffle
        
        # ë°ì´í„° ì €ì¥ì†Œ
        self.train_data = []
        self.val_data = []
        
        # ë°ì´í„° ë¡œë”©
        self._load_data()
        
        # í†µê³„ ê³„ì‚°
        self._calculate_statistics()
    
    def _load_data(self):
        """ë°ì´í„° íŒŒì¼ë“¤ì„ ë¡œë”©í•˜ëŠ” ë‚´ë¶€ ë©”ì„œë“œ"""
        try:
            # í•™ìŠµ ë°ì´í„° ë¡œë”©
            if Path(self.train_data_path).exists():
                self.train_data = self._load_jsonl(self.train_data_path)
                logger.info(f"ğŸ“¥ Loaded {len(self.train_data)} training prompts")
            else:
                logger.warning(f"âš ï¸ Training data not found: {self.train_data_path}")
            
            # ê²€ì¦ ë°ì´í„° ë¡œë”©  
            if Path(self.val_data_path).exists():
                self.val_data = self._load_jsonl(self.val_data_path)
                logger.info(f"ğŸ“¥ Loaded {len(self.val_data)} validation prompts")
            else:
                logger.warning(f"âš ï¸ Validation data not found: {self.val_data_path}")
                
        except Exception as e:
            logger.error(f"âŒ Failed to load data: {e}")
            raise
    
    def _load_jsonl(self, file_path: str) -> List[Dict]:
        """
        JSONL íŒŒì¼ ë¡œë”©
        
        Args:
            file_path (str): íŒŒì¼ ê²½ë¡œ
            
        Returns:
            List[Dict]: ë¡œë”©ëœ ë°ì´í„°
        """
        data = []
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                for line in f:
                    line = line.strip()
                    if line:
                        item = json.loads(line)
                        data.append(item)
            
            logger.debug(f"âœ… Loaded {len(data)} items from {file_path}")
            return data
            
        except Exception as e:
            logger.error(f"âŒ Failed to load {file_path}: {e}")
            return []
    
    def _calculate_statistics(self):
        """ë°ì´í„° í†µê³„ ê³„ì‚°"""
        self.stats = {
            'train_count': len(self.train_data),
            'val_count': len(self.val_data),
            'categories': {},
            'difficulties': {},
            'avg_prompt_length': 0
        }
        
        # ì „ì²´ ë°ì´í„° ë¶„ì„
        all_data = self.train_data + self.val_data
        
        if all_data:
            # ì¹´í…Œê³ ë¦¬ë³„ í†µê³„
            for item in all_data:
                category = item.get('category', 'unknown')
                difficulty = item.get('difficulty', 'unknown')
                
                self.stats['categories'][category] = self.stats['categories'].get(category, 0) + 1
                self.stats['difficulties'][difficulty] = self.stats['difficulties'].get(difficulty, 0) + 1
            
            # í‰ê·  í”„ë¡¬í”„íŠ¸ ê¸¸ì´
            prompt_lengths = [len(item.get('user_prompt', '')) for item in all_data]
            self.stats['avg_prompt_length'] = sum(prompt_lengths) / len(prompt_lengths)
        
        logger.info(f"ğŸ“Š Data statistics: {self.stats}")
    
    def get_training_batch(self, batch_size: int, shuffle: Optional[bool] = None) -> List[str]:
        """
        í•™ìŠµìš© ë°°ì¹˜ ìƒì„±
        
        Args:
            batch_size (int): ë°°ì¹˜ í¬ê¸°
            shuffle (bool, optional): ì…”í”Œ ì—¬ë¶€ (Noneì´ë©´ ê¸°ë³¸ ì„¤ì • ì‚¬ìš©)
            
        Returns:
            List[str]: í”„ë¡¬í”„íŠ¸ ë°°ì¹˜
        """
        if not self.train_data:
            logger.warning("âš ï¸ No training data available")
            return []
        
        # ì…”í”Œ ì„¤ì • ê²°ì •
        if shuffle is None:
            shuffle = self.batch_shuffle
        
        # ë°ì´í„° ë³µì‚¬ ë° ì…”í”Œ
        data = self.train_data.copy()
        if shuffle:
            random.shuffle(data)
        
        # ë°°ì¹˜ ì¶”ì¶œ
        batch = data[:batch_size]
        prompts = [item.get('user_prompt', '') for item in batch]
        
        logger.debug(f"ğŸ“¦ Generated training batch: {len(prompts)} prompts")
        return prompts
    
    def get_validation_data(self) -> List[Dict]:
        """
        ì „ì²´ ê²€ì¦ ë°ì´í„° ë°˜í™˜
        
        Returns:
            List[Dict]: ê²€ì¦ ë°ì´í„°
        """
        return self.val_data.copy()
    
    def get_category_batch(self, category: str, batch_size: int) -> List[str]:
        """
        íŠ¹ì • ì¹´í…Œê³ ë¦¬ì˜ ë°°ì¹˜ ìƒì„±
        
        Args:
            category (str): ì¹´í…Œê³ ë¦¬ ì´ë¦„
            batch_size (int): ë°°ì¹˜ í¬ê¸°
            
        Returns:
            List[str]: ì¹´í…Œê³ ë¦¬ë³„ í”„ë¡¬í”„íŠ¸ ë°°ì¹˜
        """
        # ì¹´í…Œê³ ë¦¬ í•„í„°ë§
        category_data = [
            item for item in self.train_data 
            if item.get('category') == category
        ]
        
        if not category_data:
            logger.warning(f"âš ï¸ No data found for category: {category}")
            return []
        
        # ë°°ì¹˜ ìƒì„±
        random.shuffle(category_data)
        batch = category_data[:batch_size]
        prompts = [item.get('user_prompt', '') for item in batch]
        
        logger.debug(f"ğŸ“¦ Generated {category} batch: {len(prompts)} prompts")
        return prompts
    
    def get_difficulty_batch(self, difficulty: str, batch_size: int) -> List[str]:
        """
        íŠ¹ì • ë‚œì´ë„ì˜ ë°°ì¹˜ ìƒì„±
        
        Args:
            difficulty (str): ë‚œì´ë„ ë ˆë²¨
            batch_size (int): ë°°ì¹˜ í¬ê¸°
            
        Returns:
            List[str]: ë‚œì´ë„ë³„ í”„ë¡¬í”„íŠ¸ ë°°ì¹˜
        """
        # ë‚œì´ë„ í•„í„°ë§
        difficulty_data = [
            item for item in self.train_data 
            if item.get('difficulty') == difficulty
        ]
        
        if not difficulty_data:
            logger.warning(f"âš ï¸ No data found for difficulty: {difficulty}")
            return []
        
        # ë°°ì¹˜ ìƒì„±
        random.shuffle(difficulty_data)
        batch = difficulty_data[:batch_size]
        prompts = [item.get('user_prompt', '') for item in batch]
        
        logger.debug(f"ğŸ“¦ Generated {difficulty} batch: {len(prompts)} prompts")
        return prompts
    
    def get_balanced_batch(self, batch_size: int) -> List[str]:
        """
        ì¹´í…Œê³ ë¦¬ë³„ë¡œ ê· í˜•ì¡íŒ ë°°ì¹˜ ìƒì„±
        
        Args:
            batch_size (int): ë°°ì¹˜ í¬ê¸°
            
        Returns:
            List[str]: ê· í˜•ì¡íŒ í”„ë¡¬í”„íŠ¸ ë°°ì¹˜
        """
        if not self.train_data:
            return []
        
        # ì¹´í…Œê³ ë¦¬ë³„ ë°ì´í„° ë¶„ë¥˜
        category_data = {}
        for item in self.train_data:
            category = item.get('category', 'unknown')
            if category not in category_data:
                category_data[category] = []
            category_data[category].append(item)
        
        # ê° ì¹´í…Œê³ ë¦¬ì—ì„œ ê· ë“±í•˜ê²Œ ì„ íƒ
        balanced_batch = []
        categories = list(category_data.keys())
        per_category = max(1, batch_size // len(categories))
        
        for category in categories:
            if len(balanced_batch) >= batch_size:
                break
                
            category_items = random.sample(
                category_data[category], 
                min(per_category, len(category_data[category]))
            )
            balanced_batch.extend(category_items)
        
        # ë¶€ì¡±í•œ ê²½ìš° ëœë¤í•˜ê²Œ ì¶”ê°€
        if len(balanced_batch) < batch_size:
            remaining = batch_size - len(balanced_batch)
            additional = random.sample(self.train_data, remaining)
            balanced_batch.extend(additional)
        
        # ë°°ì¹˜ í¬ê¸° ë§ì¶”ê¸°
        balanced_batch = balanced_batch[:batch_size]
        prompts = [item.get('user_prompt', '') for item in balanced_batch]
        
        logger.debug(f"ğŸ“¦ Generated balanced batch: {len(prompts)} prompts")
        return prompts
    
    def get_statistics(self) -> Dict:
        """ë°ì´í„° í†µê³„ ë°˜í™˜"""
        return self.stats.copy()
    
    def save_batch_results(self, 
                          prompts: List[str], 
                          enhanced_prompts: List[str],
                          rewards: List[float],
                          save_path: str):
        """
        ë°°ì¹˜ ê²°ê³¼ ì €ì¥
        
        Args:
            prompts (List[str]): ì›ë³¸ í”„ë¡¬í”„íŠ¸ë“¤
            enhanced_prompts (List[str]): ê°œì„ ëœ í”„ë¡¬í”„íŠ¸ë“¤  
            rewards (List[float]): ë³´ìƒ ê°’ë“¤
            save_path (str): ì €ì¥ ê²½ë¡œ
        """
        try:
            results = []
            for i in range(len(prompts)):
                result = {
                    'user_prompt': prompts[i],
                    'enhanced_prompt': enhanced_prompts[i] if i < len(enhanced_prompts) else '',
                    'reward': rewards[i] if i < len(rewards) else 0.0,
                    'improvement': len(enhanced_prompts[i]) - len(prompts[i]) if i < len(enhanced_prompts) else 0
                }
                results.append(result)
            
            # JSONL í˜•ì‹ìœ¼ë¡œ ì €ì¥
            with open(save_path, 'w', encoding='utf-8') as f:
                for result in results:
                    f.write(json.dumps(result, ensure_ascii=False) + '\n')
            
            logger.info(f"ğŸ’¾ Batch results saved: {save_path}")
            
        except Exception as e:
            logger.error(f"âŒ Failed to save batch results: {e}")

# í˜¸í™˜ì„±ì„ ìœ„í•œ ë³„ì¹­ ìƒì„±
DataLoader = PromptDataLoader

def create_sample_data(train_path: str = "train_prompts.jsonl", 
                      val_path: str = "val_prompts.jsonl"):
    """
    ìƒ˜í”Œ ë°ì´í„° ìƒì„± í•¨ìˆ˜ (í…ŒìŠ¤íŠ¸ìš©)
    
    Args:
        train_path (str): í•™ìŠµ ë°ì´í„° ì €ì¥ ê²½ë¡œ
        val_path (str): ê²€ì¦ ë°ì´í„° ì €ì¥ ê²½ë¡œ
    """
    # ìƒ˜í”Œ í•™ìŠµ ë°ì´í„°
    train_samples = [
        {"user_prompt": "a cat", "category": "basic", "difficulty": "easy"},
        {"user_prompt": "sunset", "category": "basic", "difficulty": "easy"},
        {"user_prompt": "beautiful woman", "category": "complex", "difficulty": "medium"},
        {"user_prompt": "mountain landscape", "category": "photography", "difficulty": "medium"},
        {"user_prompt": "abstract art", "category": "creative", "difficulty": "hard"},
    ]
    
    # ìƒ˜í”Œ ê²€ì¦ ë°ì´í„°
    val_samples = [
        {"user_prompt": "dog", "category": "basic", "difficulty": "easy"},
        {"user_prompt": "city skyline", "category": "photography", "difficulty": "medium"},
    ]
    
    # íŒŒì¼ ì €ì¥
    try:
        with open(train_path, 'w', encoding='utf-8') as f:
            for sample in train_samples:
                f.write(json.dumps(sample, ensure_ascii=False) + '\n')
        
        with open(val_path, 'w', encoding='utf-8') as f:
            for sample in val_samples:
                f.write(json.dumps(sample, ensure_ascii=False) + '\n')
        
        logger.info(f"âœ… Sample data created: {train_path}, {val_path}")
        
    except Exception as e:
        logger.error(f"âŒ Failed to create sample data: {e}")


if __name__ == "__main__":
    # Data Loader í…ŒìŠ¤íŠ¸ ì½”ë“œ
    print("ğŸ§ª Data Loader Test")
    print("=" * 25)
    
    try:
        # ìƒ˜í”Œ ë°ì´í„° ìƒì„±
        create_sample_data()
        
        # ë°ì´í„° ë¡œë” ì´ˆê¸°í™”
        loader = PromptDataLoader()
        
        print("âœ… Data Loader initialized successfully")
        print(f"ğŸ“Š Statistics: {loader.get_statistics()}")
        
        # ë°°ì¹˜ ìƒì„± í…ŒìŠ¤íŠ¸
        print("\nğŸ”„ Testing batch generation:")
        
        # ì¼ë°˜ ë°°ì¹˜
        batch = loader.get_training_batch(batch_size=3)
        print(f"  Training batch: {batch}")
        
        # ì¹´í…Œê³ ë¦¬ë³„ ë°°ì¹˜
        category_batch = loader.get_category_batch("basic", batch_size=2)
        print(f"  Basic category batch: {category_batch}")
        
        # ê· í˜•ì¡íŒ ë°°ì¹˜
        balanced_batch = loader.get_balanced_batch(batch_size=4)
        print(f"  Balanced batch: {balanced_batch}")
        
        # ê²€ì¦ ë°ì´í„°
        val_data = loader.get_validation_data()
        print(f"  Validation data: {len(val_data)} items")
        
        print("\nâœ… All tests passed!")
        
    except Exception as e:
        print(f"âŒ Test failed: {e}")
    
    print("\nUsage:")
    print("from utils.data_loader import PromptDataLoader")
    print("loader = PromptDataLoader()")
    print("batch = loader.get_training_batch(batch_size=4)") 