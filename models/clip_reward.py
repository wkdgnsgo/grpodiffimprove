"""
CLIP Reward Calculator
=====================

CLIP ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ì›ë³¸ user promptì™€ ìƒì„±ëœ ì´ë¯¸ì§€ ê°„ì˜ ìœ ì‚¬ë„ë¥¼ ê³„ì‚°í•˜ëŠ” ëª¨ë“ˆì…ë‹ˆë‹¤.

í•µì‹¬ íŠ¹ì§•:
- Enhanced promptê°€ ì•„ë‹Œ ì›ë³¸ user promptë§Œ ì‚¬ìš©
- ìœ ì‚¬ë„ 1.0ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ë†’ì€ ë³´ìƒ
- ê°„ë‹¨í•˜ê³  ì§ê´€ì ì¸ ë³´ìƒ ê³„ì‚°

Author: AI Assistant
Date: 2025-01-22
"""

import torch
import torch.nn.functional as F
from transformers import CLIPProcessor, CLIPModel
from PIL import Image
from typing import List, Dict, Optional, Union, Tuple
import logging
import numpy as np

logger = logging.getLogger(__name__)

class CLIPRewardCalculator:
    """
    CLIPì„ ì‚¬ìš©í•˜ì—¬ user promptì™€ ì´ë¯¸ì§€ ê°„ì˜ ìœ ì‚¬ë„ ê¸°ë°˜ ë³´ìƒì„ ê³„ì‚°í•˜ëŠ” í´ë˜ìŠ¤
    
    í•µì‹¬ ì›ë¦¬:
    1. ì›ë³¸ user promptì™€ ì´ë¯¸ì§€ë¥¼ CLIPìœ¼ë¡œ ì¸ì½”ë”©
    2. ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚° (0~1 ë²”ìœ„)
    3. ìœ ì‚¬ë„ê°€ 1ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ë†’ì€ ë³´ìƒ
    
    ì£¼ì˜: Enhanced promptê°€ ì•„ë‹Œ ì›ë³¸ user promptë§Œ ì‚¬ìš©!
    """
    
    def __init__(self,
                 model_name: str = "openai/clip-vit-base-patch32",
                 device: str = "auto"):
        """
        CLIP Reward Calculator ì´ˆê¸°í™”
        
        Args:
            model_name (str): ì‚¬ìš©í•  CLIP ëª¨ë¸ ì´ë¦„
            device (str): ë””ë°”ì´ìŠ¤ ì„¤ì • ("auto", "mps", "cuda", "cpu")
        """
        self.model_name = model_name
        
        # ë””ë°”ì´ìŠ¤ ìë™ ì„ íƒ (Multi-GPU ì§€ì›)
        if device == "auto":
            try:
                import sys
                import os
                sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
                from gpu_config import get_device_for_model
                device_str = get_device_for_model('clip')
                self.device = torch.device(device_str)
                logger.info(f"ğŸš€ Using assigned GPU for CLIP: {device_str}")
            except ImportError:
                if torch.backends.mps.is_available():
                    self.device = torch.device("mps")
                    logger.info("ğŸ Using Apple Silicon MPS for CLIP")
                elif torch.cuda.is_available():
                    self.device = torch.device("cuda")
                    logger.info("ğŸš€ Using CUDA GPU for CLIP")
                else:
                    self.device = torch.device("cpu")
                    logger.info("ğŸ’» Using CPU for CLIP")
        else:
            self.device = torch.device(device)
        
        # ëª¨ë¸ ë¡œë“œ
        self._load_model()
        
        logger.info(f"âœ… CLIP Reward Calculator initialized: {self.model_name}")
    
    def _load_model(self):
        """CLIP ëª¨ë¸ê³¼ í”„ë¡œì„¸ì„œ ë¡œë“œ"""
        try:
            logger.info(f"ğŸ“¥ Loading CLIP model: {self.model_name}")
            
            # CLIP í”„ë¡œì„¸ì„œ ë¡œë“œ
            self.processor = CLIPProcessor.from_pretrained(self.model_name)
            
            # CLIP ëª¨ë¸ ë¡œë“œ
            self.model = CLIPModel.from_pretrained(
                self.model_name,
                torch_dtype=torch.float16 if self.device.type in ['cuda', 'mps'] else torch.float32
            )
            
            # ë””ë°”ì´ìŠ¤ë¡œ ì´ë™
            self.model = self.model.to(self.device)
            self.model.eval()  # í‰ê°€ ëª¨ë“œ ì„¤ì •
            
            logger.info(f"âœ… CLIP model loaded successfully on {self.device}")
            
        except Exception as e:
            logger.error(f"âŒ Failed to load CLIP model: {e}")
            raise RuntimeError(f"CLIP model loading failed: {e}")
    
    def calculate_reward(self, 
                        user_prompt: str, 
                        image: Image.Image) -> float:
        """
        ì›ë³¸ user promptì™€ ì´ë¯¸ì§€ ê°„ì˜ ìœ ì‚¬ë„ ê¸°ë°˜ ë³´ìƒ ê³„ì‚°
        
        Args:
            user_prompt (str): ì›ë³¸ ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸ (enhanced prompt ì•„ë‹˜!)
            image (PIL.Image.Image): ìƒì„±ëœ ì´ë¯¸ì§€
            
        Returns:
            float: ìœ ì‚¬ë„ ë³´ìƒ (0.0 ~ 1.0, 1.0ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ì¢‹ìŒ)
            
        Example:
            reward = calculator.calculate_reward("a cat", generated_image)
            # reward: 0.85 (ë†’ì€ ìœ ì‚¬ë„)
        """
        try:
            # ì…ë ¥ ì „ì²˜ë¦¬
            inputs = self.processor(
                text=[user_prompt], 
                images=[image], 
                return_tensors="pt", 
                padding=True
            )
            
            # ë””ë°”ì´ìŠ¤ë¡œ ì´ë™
            inputs = {k: v.to(self.device) for k, v in inputs.items()}
            
            # CLIPìœ¼ë¡œ íŠ¹ì„± ì¶”ì¶œ
            with torch.no_grad():
                outputs = self.model(**inputs)
                
                # ì´ë¯¸ì§€ì™€ í…ìŠ¤íŠ¸ ì„ë² ë”© ì¶”ì¶œ
                image_embeds = outputs.image_embeds
                text_embeds = outputs.text_embeds
                
                # ì„ë² ë”© ì •ê·œí™” (ì‚¬ìš©ì ì œì‹œ ë°©ì‹ìœ¼ë¡œ í†µì¼)
                image_embeds = image_embeds / image_embeds.norm(dim=-1, keepdim=True)
                text_embeds = text_embeds / text_embeds.norm(dim=-1, keepdim=True)
                
                # ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚° (0~1 ë²”ìœ„)
                similarity = torch.cosine_similarity(image_embeds, text_embeds, dim=-1)
                
                # ìœ ì‚¬ë„ë¥¼ 0~1 ë²”ìœ„ë¡œ ë³€í™˜ (cosine similarityëŠ” -1~1 ë²”ìœ„)
                reward = (similarity.item() + 1.0) / 2.0
                
                logger.info(f"ğŸ¯ Reward: {reward:.4f} for user prompt: '{user_prompt}'")
                
                return reward
                
        except Exception as e:
            logger.warning(f"âš ï¸ Reward calculation failed: {e}")
            # ì‹¤íŒ¨ ì‹œ ì¤‘ê°„ ë³´ìƒ ë°˜í™˜
            return 0.5
    
    def calculate_rewards_batch(self, 
                               user_prompts: List[str], 
                               images: List[Image.Image]) -> List[float]:
        """
        ë°°ì¹˜ë¡œ ì—¬ëŸ¬ prompt-image ìŒì˜ ë³´ìƒ ê³„ì‚°
        
        Args:
            user_prompts (List[str]): ì›ë³¸ ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸ë“¤
            images (List[Image.Image]): ìƒì„±ëœ ì´ë¯¸ì§€ë“¤
            
        Returns:
            List[float]: ê° ìŒì˜ ìœ ì‚¬ë„ ë³´ìƒë“¤
        """
        if len(user_prompts) != len(images):
            raise ValueError(f"Prompts({len(user_prompts)}) and images({len(images)}) count mismatch")
        
        rewards = []
        for prompt, image in zip(user_prompts, images):
            reward = self.calculate_reward(prompt, image)
            rewards.append(reward)
        
        logger.info(f"ğŸ“Š Batch rewards calculated: avg={np.mean(rewards):.3f}, min={min(rewards):.3f}, max={max(rewards):.3f}")
        return rewards
    
    def get_detailed_similarity(self, 
                               user_prompt: str, 
                               image: Image.Image) -> Dict[str, float]:
        """
        ìƒì„¸í•œ ìœ ì‚¬ë„ ì •ë³´ ë°˜í™˜
        
        Returns:
            Dict with 'raw_similarity', 'reward', and 'confidence'
        """
        try:
            inputs = self.processor(
                text=[user_prompt], 
                images=[image], 
                return_tensors="pt", 
                padding=True
            )
            inputs = {k: v.to(self.device) for k, v in inputs.items()}
            
            with torch.no_grad():
                outputs = self.model(**inputs)
                
                image_embeds = outputs.image_embeds / outputs.image_embeds.norm(dim=-1, keepdim=True)
                text_embeds = outputs.text_embeds / outputs.text_embeds.norm(dim=-1, keepdim=True)
                
                # ì›ì‹œ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ (-1~1)
                raw_similarity = torch.cosine_similarity(image_embeds, text_embeds, dim=-1).item()
                
                # ë³´ìƒ (0~1)
                reward = (raw_similarity + 1.0) / 2.0
                
                # ì‹ ë¢°ë„ (ì ˆëŒ“ê°’ì´ í´ìˆ˜ë¡ í™•ì‹ )
                confidence = abs(raw_similarity)
                
                return {
                    'raw_similarity': raw_similarity,
                    'reward': reward,
                    'confidence': confidence,
                    'user_prompt': user_prompt
                }
                
        except Exception as e:
            logger.error(f"âŒ Detailed similarity calculation failed: {e}")
            return {
                'raw_similarity': 0.0,
                'reward': 0.5,
                'confidence': 0.0,
                'user_prompt': user_prompt,
                'error': str(e)
            }
    
    def get_model_info(self) -> Dict:
        """ëª¨ë¸ ì •ë³´ ë°˜í™˜"""
        return {
            'model_name': self.model_name,
            'device': str(self.device),
            'purpose': 'User prompt to image similarity reward',
            'reward_range': '0.0 ~ 1.0 (higher is better)'
        }

# í…ŒìŠ¤íŠ¸ìš© ë”ë¯¸ ì´ë¯¸ì§€ ìƒì„± í•¨ìˆ˜
def create_dummy_image(prompt: str, size: Tuple[int, int] = (256, 256)) -> Image.Image:
    """
    í…ŒìŠ¤íŠ¸ìš© ë”ë¯¸ ì´ë¯¸ì§€ ìƒì„± (ì‹¤ì œ ì´ë¯¸ì§€ ìƒì„± ì „ í…ŒìŠ¤íŠ¸ìš©)
    
    Args:
        prompt (str): í”„ë¡¬í”„íŠ¸ (ìƒ‰ìƒ ê²°ì •ìš©)
        size (Tuple[int, int]): ì´ë¯¸ì§€ í¬ê¸°
        
    Returns:
        PIL.Image.Image: ë”ë¯¸ ì´ë¯¸ì§€
    """
    import random
    
    # í”„ë¡¬í”„íŠ¸ ê¸°ë°˜ ìƒ‰ìƒ ìƒì„±
    random.seed(hash(prompt) % 1000000)
    color = (
        random.randint(50, 255),
        random.randint(50, 255), 
        random.randint(50, 255)
    )
    
    # ë‹¨ìƒ‰ ì´ë¯¸ì§€ ìƒì„±
    image = Image.new('RGB', size, color)
    
    return image 