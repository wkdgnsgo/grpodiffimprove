# EasyR1 vs QWEN GRPO μμΉμ  μ•μ •μ„± κΈ°λ²• λΉ„κµ

## κ°μ”

EasyR1κ³Ό λ‹¤λ¥Έ μµμ‹  LoRA νΈλ μ΄λ‹ μ‹μ¤ν…λ“¤μ—μ„ μ‚¬μ©ν•λ” μμΉμ  μ•μ •μ„± κΈ°λ²•λ“¤μ„ λ¶„μ„ν•κ³ , μ°λ¦¬ QWEN GRPO κµ¬ν„μ— μ μ©ν• λ‚΄μ©μ„ μ •λ¦¬ν•©λ‹λ‹¤.

## 1. EasyR1 λ° μµμ‹  μ—°κµ¬μ ν•µμ‹¬ μ•μ •μ„± κΈ°λ²•

### A. Stochastic Rounding (SR)

**μ¶μ²**: "Stochastic Rounding for LLM Training: Theory and Practice" (AISTATS 2025)

**ν•µμ‹¬ μ•„μ΄λ””μ–΄**:

- BF16 + Stochastic RoundingμΌλ΅ μμΉμ  μ¤μ°¨ ν•΄κ²°
- 6.7B νλΌλ―Έν„° λ¨λΈμ—μ„ 1.54x μ†λ„ ν–¥μƒ, 30% λ©”λ¨λ¦¬ μ μ•½

**κµ¬ν„**:

```python
# ν™•λ¥ μ  λ°μ¬λ¦Ό μ‹λ®¬λ μ΄μ…
if self.grpo_config.use_stochastic_rounding and self.training:
    noise = torch.randn_like(generated_logits) * 1e-6
    generated_logits = generated_logits + noise
```

### B. AdaGC (Adaptive Gradient Clipping)

**μ¶μ²**: "AdaGC: Improving Training Stability for LLM Pretraining" (2025)

**ν•µμ‹¬ μ•„μ΄λ””μ–΄**:

- νλΌλ―Έν„°λ³„ μ μ‘μ  κ·Έλλ””μ–ΈνΈ ν΄λ¦¬ν•‘
- μ§€μ μ΄λ™ ν‰κ· μΌλ΅ κ·Έλλ””μ–ΈνΈ norm μ¶”μ 

**κµ¬ν„**:

```python
def _apply_adaptive_gradient_clipping(self) -> float:
    # ν„μ¬ κ·Έλλ””μ–ΈνΈ norm κ³„μ‚°
    grad_norm = sum(param.grad.data.norm().item() ** 2
                   for param in self.model.parameters()
                   if param.grad is not None) ** 0.5

    # μ§€μ μ΄λ™ ν‰κ·  μ—…λ°μ΄νΈ
    beta = self.grpo_config.grad_clip_ema_beta
    self.grad_norm_ema = beta * self.grad_norm_ema + (1 - beta) * grad_norm

    # μ μ‘μ  ν΄λ¦¬ν•‘ μ„κ³„κ°’
    clip_threshold = self.grpo_config.grad_clip_coef * self.grad_norm_ema
```

### C. SAVEUS Optimizer κΈ°λ²•λ“¤

**μ¶μ²**: "10 Minute LoRA Training" κ°€μ΄λ“

**ν•µμ‹¬ κΈ°λ²•λ“¤**:

1. **Gradient Centralization**: `g_t = g_t - mean(g_t)`
2. **Adaptive Gradient Normalization**: `g_t = (1-Ξ±)*g_t + Ξ±*(g_t/std(g_t))`
3. **Momentum Amplification**: `g_t = g_t + amp_fac * m_t`

## 2. μ°λ¦¬ QWEN GRPO κµ¬ν„μ— μ μ©λ μ•μ •μ„± κΈ°λ²•

### β… μ μ© μ™„λ£λ κΈ°λ²•λ“¤

#### A. μ μ‘μ  κ·Έλλ””μ–ΈνΈ ν΄λ¦¬ν•‘ (AdaGC)

```python
# μ„¤μ •
use_adaptive_grad_clip: bool = True
grad_clip_ema_beta: float = 0.99  # EMA κ³„μ
grad_clip_coef: float = 1.5       # ν΄λ¦¬ν•‘ κ³„μ

# κµ¬ν„
def _apply_adaptive_gradient_clipping(self) -> float:
    grad_norm = calculate_current_grad_norm()
    self.grad_norm_ema = beta * self.grad_norm_ema + (1 - beta) * grad_norm
    clip_threshold = self.grpo_config.grad_clip_coef * self.grad_norm_ema
    if grad_norm > clip_threshold:
        apply_clipping(clip_threshold / grad_norm)
```

#### B. κ·Έλλ””μ–ΈνΈ μ¤‘μ•™ν™” (Gradient Centralization)

```python
# μ„¤μ •
use_grad_centralization: bool = True

# κµ¬ν„
def _apply_gradient_centralization(self):
    for param in self.model.parameters():
        if param.grad is not None and param.grad.dim() > 1:
            grad_mean = param.grad.mean(dim=tuple(range(1, param.grad.dim())), keepdim=True)
            param.grad = param.grad - grad_mean
```

#### C. μ μ‘μ  κ·Έλλ””μ–ΈνΈ μ •κ·ν™”

```python
# μ„¤μ •
use_grad_normalization: bool = True
grad_norm_alpha: float = 0.5

# κµ¬ν„
def _apply_gradient_normalization(self):
    for param in self.model.parameters():
        if param.grad is not None:
            grad_std = param.grad.std()
            if grad_std > 1e-8:
                normalized_grad = param.grad / (grad_std + 1e-8)
                param.grad = (1 - alpha) * param.grad + alpha * normalized_grad
```

#### D. ν™•λ¥ μ  λ°μ¬λ¦Ό μ‹λ®¬λ μ΄μ…

```python
# μ„¤μ •
use_stochastic_rounding: bool = True

# κµ¬ν„ (λ΅κ·Έ ν™•λ¥  κ³„μ‚° μ‹)
if self.grpo_config.use_stochastic_rounding and self.training:
    noise = torch.randn_like(generated_logits) * 1e-6
    generated_logits = generated_logits + noise
```

#### E. λ³΄μμ μΈ Logits ν΄λ¦¬ν•‘

```python
# μ„¤μ •
logits_clip_range: float = 20.0  # κΈ°μ΅΄ 100.0μ—μ„ 20.0μΌλ΅ λ³΄μμ μΌλ΅

# κµ¬ν„
generated_logits = torch.clamp(generated_logits,
                               min=-self.grpo_config.logits_clip_range,
                               max=self.grpo_config.logits_clip_range)
```

#### F. μ•μ „ν• λ΅κ·Έ ν™•λ¥  κ³„μ‚°

```python
# μ„¤μ •
stable_log_prob_min: float = -50.0

# κµ¬ν„ - λ‹¤λ‹¨κ³„ μ•μ „μ„± κ²€μ‚¬
1. NaN/Inf κ²€μ‚¬ λ° ν΄λ¦¬ν•‘
2. μλ°©μ  logits ν΄λ¦¬ν•‘
3. log_softmax κ²°κ³Ό κ²€μ¦
4. μµμΆ… λ΅κ·Έ ν™•λ¥  μ•μ „μ„± κ²€μ‚¬
```

### π”„ GRPO μ—…λ°μ΄νΈ μ‹ μ•μ •μ„± κΈ°λ²• μ μ© μμ„

```python
def update_grpo_policy(self, experiences):
    # ... μ†μ‹¤ κ³„μ‚° ...

    # μ—­μ „ν
    self.grpo_optimizer.zero_grad()
    total_loss.backward()

    # EasyR1 μ¤νƒ€μΌ κ·Έλλ””μ–ΈνΈ μ•μ •μ„± κΈ°λ²• μ μ©
    self.training_step += 1

    # 1. κ·Έλλ””μ–ΈνΈ μ¤‘μ•™ν™”
    if self.grpo_config.use_grad_centralization:
        self._apply_gradient_centralization()

    # 2. κ·Έλλ””μ–ΈνΈ μ •κ·ν™”
    if self.grpo_config.use_grad_normalization:
        self._apply_gradient_normalization()

    # 3. μ μ‘μ  κ·Έλλ””μ–ΈνΈ ν΄λ¦¬ν•‘
    if self.grpo_config.use_adaptive_grad_clip:
        grad_norm = self._apply_adaptive_gradient_clipping()
    else:
        grad_norm = torch.nn.utils.clip_grad_norm_(self.model.parameters(), 1.0)

    self.grpo_optimizer.step()
```

## 3. κΈ°μ΅΄ vs EasyR1 μ¤νƒ€μΌ λΉ„κµ

| ν•­λ©                  | κΈ°μ΅΄ κµ¬ν„             | EasyR1 μ¤νƒ€μΌ κ°μ„               |
| --------------------- | --------------------- | ------------------------------- |
| **κ·Έλλ””μ–ΈνΈ ν΄λ¦¬ν•‘** | κ³ μ •κ°’ (1.0)          | μ μ‘μ  (EMA κΈ°λ°)               |
| **Logits ν΄λ¦¬ν•‘**     | Β±100.0                | Β±20.0 (λ³΄μμ )                  |
| **κ·Έλλ””μ–ΈνΈ μ²λ¦¬**   | κΈ°λ³Έ ν΄λ¦¬ν•‘λ§         | μ¤‘μ•™ν™” + μ •κ·ν™” + μ μ‘μ  ν΄λ¦¬ν•‘ |
| **μμΉμ  μ•μ •μ„±**     | κΈ°λ³Έμ μΈ NaN/Inf κ²€μ‚¬ | λ‹¤λ‹¨κ³„ μ•μ „μ„± κ²€μ‚¬              |
| **ν™•λ¥ μ  λ°μ¬λ¦Ό**     | μ—†μ                  | μ‹λ®¬λ μ΄μ… μ μ©                 |
| **μ•μ •μ„± λ¨λ‹ν„°λ§**   | μ ν•μ                 | μƒμ„Έν• λ΅κΉ… λ° μ¶”μ              |

## 4. μ„±λ¥ λ° μ•μ •μ„± κΈ°λ€ ν¨κ³Ό

### A. μμΉμ  μ•μ •μ„± ν–¥μƒ

- **NaN/Inf λ°μƒ κ°μ†**: λ‹¤λ‹¨κ³„ μ•μ „μ„± κ²€μ‚¬λ΅ μλ°©
- **κ·Έλλ””μ–ΈνΈ ν­λ° λ°©μ§€**: μ μ‘μ  ν΄λ¦¬ν•‘μΌλ΅ μ•μ •μ  ν•™μµ
- **λ΅κ·Έ ν™•λ¥  μ•μ •μ„±**: λ³΄μμ μΈ ν΄λ¦¬ν•‘ λ²”μ„λ΅ μ•μ „μ„± ν™•λ³΄

### B. ν•™μµ ν¨μ¨μ„± κ°μ„ 

- **μ μ‘μ  ν•™μµλ¥ **: κ·Έλλ””μ–ΈνΈ normμ— λ”°λ¥Έ λ™μ  μ΅°μ •
- **κ·Έλλ””μ–ΈνΈ ν’μ§ ν–¥μƒ**: μ¤‘μ•™ν™” λ° μ •κ·ν™”λ΅ λ” λ‚μ€ μ—…λ°μ΄νΈ
- **λ©”λ¨λ¦¬ ν¨μ¨μ„±**: ν™•λ¥ μ  λ°μ¬λ¦ΌμΌλ΅ μ •λ°€λ„ μµμ ν™”

### C. GRPO μ•κ³ λ¦¬μ¦ μ•μ •μ„±

- **μ •μ±… μ—…λ°μ΄νΈ μ•μ •μ„±**: μ•μ „ν• μ¤‘μ”λ„ λΉ„μ¨ κ³„μ‚°
- **KL λ°μ‚° μ•μ •μ„±**: λ³΄μμ μΈ logitsλ΅ μ•μ •μ  KL μ¶”μ •
- **Reference λ¨λΈ μΌκ΄€μ„±**: λ™μΌν• μ•μ •μ„± κΈ°λ²• μ μ©

## 5. ν…μ¤νΈ λ° κ²€μ¦

### ν…μ¤νΈ μ¤ν¬λ¦½νΈ: `test_easyr1_stability.py`

```bash
python test_easyr1_stability.py
```

**ν…μ¤νΈ ν•­λ©**:

1. β… κΈ°λ³Έ ν”„λ΅¬ν”„νΈ ν–¥μƒ μ•μ •μ„±
2. β… GRPO λ΅κ·Έ ν™•λ¥  κ³„μ‚° μ•μ •μ„±
3. β… κ·Έλλ””μ–ΈνΈ μ•μ •μ„± κΈ°λ²• μ μ©
4. β… μ„¤μ •κ°’ κ²€μ¦
5. β… μ μ‘μ  ν΄λ¦¬ν•‘ EMA μ—…λ°μ΄νΈ

## 6. κ¶μ¥μ‚¬ν•­

### A. μ‹¤μ  νΈλ μ΄λ‹μ—μ„μ μ„¤μ •

```python
# μ•μ •μ„± μ°μ„  μ„¤μ • (κ¶μ¥)
grpo_config = QWENGRPOConfig(
    use_adaptive_grad_clip=True,
    grad_clip_ema_beta=0.99,
    grad_clip_coef=1.5,
    use_grad_centralization=True,
    use_grad_normalization=True,
    grad_norm_alpha=0.5,
    use_stochastic_rounding=True,
    logits_clip_range=20.0,
    stable_log_prob_min=-50.0
)
```

### B. μ„±λ¥ λ¨λ‹ν„°λ§

- κ·Έλλ””μ–ΈνΈ norm EMA μ¶”μ 
- NaN/Inf λ°μƒ λΉλ„ λ¨λ‹ν„°λ§
- μ μ‘μ  ν΄λ¦¬ν•‘ λ°λ™ λΉλ„ ν™•μΈ
- λ΅κ·Έ ν™•λ¥  μ•μ •μ„± κ²€μ¦

### C. μ μ§„μ  μ μ©

1. **1λ‹¨κ³„**: μ μ‘μ  κ·Έλλ””μ–ΈνΈ ν΄λ¦¬ν•‘λ§ ν™μ„±ν™”
2. **2λ‹¨κ³„**: κ·Έλλ””μ–ΈνΈ μ¤‘μ•™ν™” μ¶”κ°€
3. **3λ‹¨κ³„**: μ „μ²΄ EasyR1 κΈ°λ²• μ μ©
4. **4λ‹¨κ³„**: μ„±λ¥ λΉ„κµ λ° μµμ ν™”

## κ²°λ΅ 

EasyR1 μ¤νƒ€μΌμ μμΉμ  μ•μ •μ„± κΈ°λ²•λ“¤μ„ QWEN GRPO κµ¬ν„μ— μ„±κ³µμ μΌλ΅ μ μ©ν–μµλ‹λ‹¤. μ΄λ¥Ό ν†µν•΄:

- β… **μμΉμ  μ•μ •μ„± λ€ν­ ν–¥μƒ**
- β… **κ·Έλλ””μ–ΈνΈ ν’μ§ κ°μ„ **
- β… **ν•™μµ μ•μ •μ„± ν™•λ³΄**
- β… **GRPO μ•κ³ λ¦¬μ¦ μ‹ λΆ°μ„± μ¦λ€**

μ΄μ  QWEN λ¨λΈμ LoRA νΈλ μ΄λ‹μ΄ EasyR1κ³Ό μ μ‚¬ν• μμ¤€μ μμΉμ  μ•μ •μ„±μ„ κ°€μ§€κ² λμ—μµλ‹λ‹¤!
