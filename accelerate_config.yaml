compute_environment: LOCAL_MACHINE
distributed_type: MULTI_GPU
downcast_bf16: "no"
gpu_ids: "2,3,4,5"
machine_rank: 0
main_training_function: main
mixed_precision: fp16
num_machines: 1
num_processes: 4
rdzv_backend: static
same_network: true
tpu_env: []
tpu_use_cluster: false
tpu_use_sudo: false
use_cpu: false

# 메모리 최적화 설정
gradient_accumulation_steps: 2
dataloader_config:
  split_batches: true

# DeepSpeed ZeRO 스테이지 3 활성화 (전체 학습용)
deepspeed_config:
  gradient_accumulation_steps: 4
  train_batch_size: 4
  train_micro_batch_size_per_gpu: 1

  zero_optimization:
    stage: 3
    offload_optimizer:
      device: cpu
      pin_memory: true
    offload_param:
      device: cpu
      pin_memory: true
    overlap_comm: true
    contiguous_gradients: true
    sub_group_size: 1e9
    reduce_bucket_size: 1e6
    stage3_prefetch_bucket_size: 1e6
    stage3_param_persistence_threshold: 1e4
    stage3_max_live_parameters: 1e9
    stage3_max_reuse_distance: 1e9
    stage3_gather_16bit_weights_on_model_save: true

  fp16:
    enabled: true
    initial_scale_power: 16

  optimizer:
    type: AdamW
    params:
      lr: 1e-6
      weight_decay: 0.01

  activation_checkpointing:
    partition_activations: true
    cpu_checkpointing: true
    contiguous_memory_optimization: true
    number_checkpoints: null
    synchronize_checkpoint_boundary: false
    profile: false

  # GPU 메모리 최적화 (GPU 2-5 전체 학습용)
  memory_efficient_attention: true
  max_memory_MB: 38000 # GPU별 메모리 제한 (38GB)
