#!/bin/bash
# Enhanced VLM GRPO Full Training Script
# ======================================
# 
# MS Swift CoZ GRPOë¥¼ ì°¸ì¡°í•œ ì „ì²´ íŒŒë¼ë¯¸í„° í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸ì…ë‹ˆë‹¤.
# ê³ ì„±ëŠ¥ í•™ìŠµì„ ìœ„í•´ ì „ì²´ ëª¨ë¸ì„ í•™ìŠµí•©ë‹ˆë‹¤.
#
# ì‚¬ìš©ë²•:
#   bash scripts/run_full_training.sh
#
# ìš”êµ¬ì‚¬í•­:
#   - ì¶©ë¶„í•œ GPU ë©”ëª¨ë¦¬ (16GB+)
#   - DeepSpeed ì„¤ì¹˜ ê¶Œì¥
#
# Author: AI Assistant (Based on MS Swift CoZ GRPO)
# Date: 2025-01-22

echo "ğŸš€ Enhanced VLM GRPO Full Training"
echo "=================================="
echo "ğŸ“‹ Full Training ì„¤ì •:"
echo "   - Train Type: Full Parameter"
echo "   - DeepSpeed: zero2"
echo "   - High Performance: âœ…"
echo "   - Memory Requirement: High"
echo ""

# ì „ì²´ í•™ìŠµ ì‹¤í–‰
python vlm_grpo_system/run_enhanced_training.py \
    --train_type full \
    --model microsoft/DialoGPT-medium \
    --torch_dtype bfloat16 \
    --learning_rate 1e-6 \
    --per_device_train_batch_size 2 \
    --gradient_accumulation_steps 2 \
    --num_train_epochs 10 \
    --group_size 4 \
    --num_generations 7 \
    --temperature 0.9 \
    --top_p 0.9 \
    --max_length 2048 \
    --max_completion_length 1024 \
    --validation_interval 3 \
    --checkpoint_interval 5 \
    --eval_steps 50 \
    --save_steps 50 \
    --logging_steps 2 \
    --output_dir vlm_grpo_results_full \
    --log_completions \
    --use_wandb \
    --wandb_project vlm-grpo-full \
    --device auto \
    --use_flash_attention \
    --gradient_checkpointing \
    --use_deepspeed \
    --deepspeed zero2

echo ""
echo "ğŸ‰ Full Training ì™„ë£Œ!"
echo "ğŸ“Š ê²°ê³¼ í™•ì¸: vlm_grpo_results_full/" 