{
  "_comment": "VLM GRPO System Default Configuration",
  "_description": "이 파일은 VLM GRPO 시스템의 기본 설정을 포함합니다.",

  "model_settings": {
    "_comment": "모델 관련 설정",
    "vlm_model": "Qwen/Qwen2.5-VL-7B-Instruct",
    "sd_model": "stabilityai/stable-diffusion-3-medium-diffusers",
    "clip_model": "openai/clip-vit-base-patch32"
  },

  "training_settings": {
    "_comment": "학습 관련 설정",
    "learning_rate": 1e-5,
    "group_size": 4,
    "num_iterations": 50,
    "grpo_epochs": 2,
    "validation_interval": 1,
    "checkpoint_interval": 10,

    "grpo_parameters": {
      "_comment": "GRPO 알고리즘 파라미터 - 논문 기반 설정 (Shao et al. 2024)",
      "gamma": 0.99,
      "kl_beta": 0.01,
      "clip_epsilon": 0.2,
      "entropy_coeff": 0.01,
      "max_grad_norm": 1.0,
      "epsilon_std": 1e-8,
      "_paper_reference": "DeepSeekMath: Pushing the Limits of Mathematical Reasoning (Shao et al., 2024)"
    }
  },

  "data_settings": {
    "_comment": "데이터 관련 설정",
    "train_data_path": "train_prompts.jsonl",
    "val_data_path": "val_prompts.jsonl",
    "batch_shuffle": true,
    "use_balanced_batches": false
  },

  "generation_settings": {
    "_comment": "생성 관련 설정",
    "vlm_generation": {
      "max_new_tokens": 50,
      "temperature": 0.8,
      "top_p": 0.9
    },
    "sd_generation": {
      "height": 1024,
      "width": 1024,
      "num_inference_steps": 28,
      "guidance_scale": 7.0
    }
  },

  "reward_settings": {
    "_comment": "보상 계산 설정 - GRPO 논문 기반",
    "_paper_reference": "Based on GRPO verifiable rewards (Shao et al. 2024, Mroueh 2025)",

    "reward_weights": {
      "clip_similarity": 0.6,
      "image_quality": 0.3,
      "semantic_consistency": 0.1
    },
    "reward_scale": 1.0,
    "reward_offset": 0.0,
    "temperature": 1.0,

    "verifiable_rewards": {
      "_comment": "논문에서 제시하는 verifiable rewards 설정",
      "enabled": true,
      "binary_rewards": true,
      "_description": "Binary rewards (0/1) for verifiable correctness as used in DeepSeek-R1",
      "reward_clipping": {
        "enabled": true,
        "min_value": 0.0,
        "max_value": 1.0
      },
      "variance_masking": {
        "enabled": true,
        "_description": "Mask zero variance samples as suggested in DAPO paper"
      }
    },

    "advantage_calculation": {
      "_comment": "GRPO 어드밴티지 계산 설정 - 논문 기반",
      "whitening_enabled": true,
      "group_normalization": true,
      "epsilon_stabilization": 1e-8,
      "_description": "Group-based whitening as described in GRPO paper"
    }
  },

  "output_settings": {
    "_comment": "출력 관련 설정",
    "output_dir": "vlm_grpo_results",
    "save_images": true,
    "save_enhanced_prompts": true,
    "log_level": "INFO",
    "save_frequency": 1,
    "max_images_per_validation": 10
  },

  "wandb_settings": {
    "_comment": "Wandb 실험 추적 설정",
    "use_wandb": true,
    "project": "vlm-grpo-training",
    "entity": null,
    "tags": ["vlm", "grpo", "text-to-image", "verifiable-rewards"],
    "notes": "VLM GRPO training with paper-based verifiable rewards"
  },

  "system_settings": {
    "_comment": "시스템 관련 설정",
    "device": "cpu",
    "mixed_precision": false,
    "gradient_checkpointing": false,
    "memory_efficient": true
  },

  "evaluation_settings": {
    "_comment": "평가 관련 설정",
    "eval_batch_size": 10,
    "save_eval_images": true,
    "eval_categories": ["basic", "complex", "photography", "creative"],
    "eval_difficulties": ["easy", "medium", "hard"]
  }
}
