# Enhanced VLM GRPO System

MS Swift CoZ GRPOë¥¼ ì°¸ì¡°í•˜ì—¬ ê°œì„ ëœ VLM GRPO (Group Relative Policy Optimization) ì‹œìŠ¤í…œìž…ë‹ˆë‹¤.  
**LoRA ë²„ì „ê³¼ ì „ì²´ í•™ìŠµ ë²„ì „ì„ ëª¨ë‘ ì§€ì›**í•˜ì—¬ ë‹¤ì–‘í•œ í•˜ë“œì›¨ì–´ í™˜ê²½ì—ì„œ íš¨ìœ¨ì ì¸ í•™ìŠµì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.

## ðŸš€ ì£¼ìš” ê°œì„ ì‚¬í•­

### 1. MS Swift ìŠ¤íƒ€ì¼ ì§€ì›

- **MS Swift í˜¸í™˜ ëª…ë ¹í–‰ ì¸í„°íŽ˜ì´ìŠ¤**
- `--train_type {full,lora,qlora}` ì˜µì…˜ìœ¼ë¡œ í•™ìŠµ ëª¨ë“œ ì„ íƒ
- `--lora_rank`, `--lora_alpha`, `--target_modules` ë“± MS Swift í‘œì¤€ ì˜µì…˜
- `--deepspeed zero2/zero3` ë¶„ì‚° í•™ìŠµ ì§€ì›

### 2. ìœ ì—°í•œ í•™ìŠµ ëª¨ë“œ

| í•™ìŠµ ëª¨ë“œ | ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰     | í•™ìŠµ ì†ë„ | ì„±ëŠ¥ | ì¶”ì²œ ìƒí™©                  |
| --------- | ----------------- | --------- | ---- | -------------------------- |
| **LoRA**  | ë‚®ìŒ (4-8GB)      | ë¹ ë¦„      | ì¢‹ìŒ | ì¼ë°˜ì ì¸ ìƒí™©, ë©”ëª¨ë¦¬ ì œí•œ |
| **QLoRA** | ë§¤ìš° ë‚®ìŒ (2-4GB) | ë³´í†µ      | ì¢‹ìŒ | ê·¹ë„ì˜ ë©”ëª¨ë¦¬ ì œí•œ         |
| **Full**  | ë†’ìŒ (16GB+)      | ëŠë¦¼      | ìµœê³  | ì¶©ë¶„í•œ ë¦¬ì†ŒìŠ¤, ìµœê³  ì„±ëŠ¥   |

### 3. ìžë™ í•˜ë“œì›¨ì–´ ìµœì í™”

- **Apple Silicon MPS** ìžë™ ê°ì§€ ë° í™œìš©
- **CUDA GPU** ìžë™ ìµœì í™”
- **CPU í´ë°±** ì§€ì›
- **ë©”ëª¨ë¦¬ íš¨ìœ¨ì  Attention** (Flash Attention, Attention Slicing)

## ðŸ“ í´ë” êµ¬ì¡°

```
vlm_grpo_system/
â”œâ”€â”€ models/                    # í•µì‹¬ AI ëª¨ë¸ë“¤
â”‚   â”œâ”€â”€ vlm_wrapper.py        # VLM í”„ë¡¬í”„íŠ¸ ê°œì„  (LoRA ì§€ì›)
â”‚   â”œâ”€â”€ sd_generator.py       # Stable Diffusion 3 ìƒì„±ê¸°
â”‚   â””â”€â”€ clip_reward.py        # CLIP ê¸°ë°˜ ë³´ìƒ ê³„ì‚°ê¸°
â”œâ”€â”€ training/                  # GRPO í•™ìŠµ ì•Œê³ ë¦¬ì¦˜
â”‚   â”œâ”€â”€ grpo_trainer.py       # ê¸°ë³¸ GRPO íŠ¸ë ˆì´ë„ˆ
â”‚   â””â”€â”€ enhanced_grpo.py      # MS Swift ìŠ¤íƒ€ì¼ íŠ¸ë ˆì´ë„ˆ
â”œâ”€â”€ utils/                     # ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤
â”‚   â””â”€â”€ data_loader.py        # ë°ì´í„° ë¡œë”
â”œâ”€â”€ evaluation/                # ê²€ì¦ ì‹œìŠ¤í…œ
â”‚   â””â”€â”€ validator.py          # ì„±ëŠ¥ ê²€ì¦ê¸°
â”œâ”€â”€ integration/               # ì‹œìŠ¤í…œ í†µí•©
â”‚   â”œâ”€â”€ main_trainer.py       # ê¸°ë³¸ í†µí•© íŠ¸ë ˆì´ë„ˆ
â”‚   â”œâ”€â”€ main_trainer_enhanced.py # ê°œì„ ëœ í†µí•© íŠ¸ë ˆì´ë„ˆ
â”‚   â””â”€â”€ wandb_logger.py       # ì‹¤í—˜ ì¶”ì 
â”œâ”€â”€ config/                    # ì„¤ì • íŒŒì¼ë“¤
â”‚   â””â”€â”€ default_config.json   # ê¸°ë³¸ ì„¤ì •
â”œâ”€â”€ scripts/                   # ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸ë“¤
â”‚   â”œâ”€â”€ run_lora_training.sh  # LoRA í•™ìŠµ
â”‚   â”œâ”€â”€ run_full_training.sh  # ì „ì²´ í•™ìŠµ
â”‚   â””â”€â”€ run_test_training.sh  # í…ŒìŠ¤íŠ¸ í•™ìŠµ
â”œâ”€â”€ data/                      # ë°ì´í„° ì €ìž¥ì†Œ
â”œâ”€â”€ run_enhanced_training.py   # MS Swift ìŠ¤íƒ€ì¼ ì‹¤í–‰ê¸°
â””â”€â”€ README_Enhanced.md         # ì´ ë¬¸ì„œ
```

## ðŸ”§ ì„¤ì¹˜ ë° ì„¤ì •

### 1. ê¸°ë³¸ ì˜ì¡´ì„± ì„¤ì¹˜

```bash
# ê¸°ë³¸ íŒ¨í‚¤ì§€
pip install torch torchvision torchaudio
pip install transformers diffusers accelerate
pip install pillow numpy opencv-python
pip install wandb datasets

# LoRA ì§€ì›ì„ ìœ„í•œ PEFT
pip install peft

# ì„ íƒì : DeepSpeed (ë¶„ì‚° í•™ìŠµ)
pip install deepspeed

# ì„ íƒì : Flash Attention (ë©”ëª¨ë¦¬ ìµœì í™”)
pip install flash-attn --no-build-isolation
```

### 2. Apple Silicon ìµœì í™” (M1/M2 Mac)

```bash
# MPS ë°±ì—”ë“œ í™œì„±í™” í™•ì¸
python -c "import torch; print(f'MPS available: {torch.backends.mps.is_available()}')"
```

## ðŸš€ ë¹ ë¥¸ ì‹œìž‘

### 1. í…ŒìŠ¤íŠ¸ ì‹¤í–‰ (ê¶Œìž¥)

```bash
# ì‹œìŠ¤í…œì´ ì •ìƒ ìž‘ë™í•˜ëŠ”ì§€ ë¹ ë¥¸ í…ŒìŠ¤íŠ¸
bash vlm_grpo_system/scripts/run_test_training.sh
```

### 2. LoRA í•™ìŠµ (ë©”ëª¨ë¦¬ íš¨ìœ¨ì )

```bash
# LoRA í•™ìŠµ ì‹¤í–‰
bash vlm_grpo_system/scripts/run_lora_training.sh
```

### 3. ì „ì²´ í•™ìŠµ (ê³ ì„±ëŠ¥)

```bash
# ì „ì²´ íŒŒë¼ë¯¸í„° í•™ìŠµ ì‹¤í–‰ (ì¶©ë¶„í•œ GPU ë©”ëª¨ë¦¬ í•„ìš”)
bash vlm_grpo_system/scripts/run_full_training.sh
```

## ðŸŽ¯ MS Swift ìŠ¤íƒ€ì¼ ì‚¬ìš©ë²•

### ê¸°ë³¸ ëª…ë ¹ì–´ êµ¬ì¡°

```bash
python vlm_grpo_system/run_enhanced_training.py \
    --train_type {full,lora,qlora} \
    --model MODEL_NAME \
    --lora_rank 8 \
    --lora_alpha 32 \
    --learning_rate 1e-5 \
    --output_dir OUTPUT_PATH
```

### LoRA í•™ìŠµ ì˜ˆì‹œ

```bash
python vlm_grpo_system/run_enhanced_training.py \
    --train_type lora \
    --model microsoft/DialoGPT-medium \
    --lora_rank 8 \
    --lora_alpha 32 \
    --target_modules all-linear \
    --learning_rate 1e-5 \
    --per_device_train_batch_size 4 \
    --num_train_epochs 20 \
    --output_dir vlm_grpo_lora_results \
    --use_wandb \
    --log_completions
```

### ì „ì²´ í•™ìŠµ ì˜ˆì‹œ

```bash
python vlm_grpo_system/run_enhanced_training.py \
    --train_type full \
    --model microsoft/DialoGPT-medium \
    --learning_rate 1e-6 \
    --per_device_train_batch_size 2 \
    --gradient_accumulation_steps 2 \
    --num_train_epochs 10 \
    --use_deepspeed \
    --deepspeed zero2 \
    --output_dir vlm_grpo_full_results \
    --use_wandb
```

### QLoRA í•™ìŠµ ì˜ˆì‹œ (ê·¹ë„ì˜ ë©”ëª¨ë¦¬ ì ˆì•½)

```bash
python vlm_grpo_system/run_enhanced_training.py \
    --train_type qlora \
    --model microsoft/DialoGPT-medium \
    --lora_rank 16 \
    --lora_alpha 64 \
    --learning_rate 2e-4 \
    --per_device_train_batch_size 1 \
    --gradient_accumulation_steps 4 \
    --output_dir vlm_grpo_qlora_results
```

## âš™ï¸ ì£¼ìš” ì„¤ì • ì˜µì…˜

### í•™ìŠµ íƒ€ìž… ì„¤ì •

- `--train_type full`: ì „ì²´ íŒŒë¼ë¯¸í„° í•™ìŠµ (ìµœê³  ì„±ëŠ¥, ë†’ì€ ë©”ëª¨ë¦¬)
- `--train_type lora`: LoRA í•™ìŠµ (ê· í˜•ìž¡ížŒ ì„±ëŠ¥ê³¼ íš¨ìœ¨ì„±)
- `--train_type qlora`: QLoRA í•™ìŠµ (ìµœê³  íš¨ìœ¨ì„±, ë‚®ì€ ë©”ëª¨ë¦¬)

### LoRA ì„¤ì •

- `--lora_rank 8`: LoRA rank (ë‚®ì„ìˆ˜ë¡ ë©”ëª¨ë¦¬ íš¨ìœ¨ì )
- `--lora_alpha 32`: LoRA alpha (í•™ìŠµ ê°•ë„ ì¡°ì ˆ)
- `--target_modules all-linear`: ì ìš©í•  ëª¨ë“ˆ (MS Swift ìŠ¤íƒ€ì¼)

### í•˜ë“œì›¨ì–´ ìµœì í™”

- `--device auto`: ìžë™ ë””ë°”ì´ìŠ¤ ì„ íƒ (MPS/CUDA/CPU)
- `--torch_dtype bfloat16`: ë©”ëª¨ë¦¬ íš¨ìœ¨ì  ë°ì´í„° íƒ€ìž…
- `--use_flash_attention`: Flash Attention ì‚¬ìš©
- `--gradient_checkpointing`: ê·¸ëž˜ë””ì–¸íŠ¸ ì²´í¬í¬ì¸íŒ…

### ë¶„ì‚° í•™ìŠµ

- `--use_deepspeed`: DeepSpeed í™œì„±í™”
- `--deepspeed zero2`: ZeRO Stage 2 (ë©”ëª¨ë¦¬ ìµœì í™”)
- `--deepspeed zero3`: ZeRO Stage 3 (ê·¹ë„ì˜ ë©”ëª¨ë¦¬ ìµœì í™”)

## ðŸ“Š ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§

### Wandb í†µí•©

```bash
# Wandb ë¡œê·¸ì¸ (ìµœì´ˆ 1íšŒ)
wandb login

# Wandbì™€ í•¨ê»˜ í•™ìŠµ
python vlm_grpo_system/run_enhanced_training.py \
    --use_wandb \
    --wandb_project my-vlm-grpo \
    --wandb_run_name experiment-1
```

### ì‹¤ì‹œê°„ ë¡œê·¸ í™•ì¸

```bash
# í•™ìŠµ ë¡œê·¸ ì‹¤ì‹œê°„ í™•ì¸
tail -f vlm_grpo_training.log
```

## ðŸ” ê²°ê³¼ ë¶„ì„

### ì²´í¬í¬ì¸íŠ¸ êµ¬ì¡°

```
vlm_grpo_results/
â”œâ”€â”€ checkpoint_iter_10/       # ì¤‘ê°„ ì²´í¬í¬ì¸íŠ¸
â”‚   â”œâ”€â”€ training_stats.json
â”‚   â””â”€â”€ config.json
â”œâ”€â”€ checkpoint_iter_20/
â””â”€â”€ final_results.json        # ìµœì¢… ê²°ê³¼
```

### LoRA ì–´ëŒ‘í„° ì‚¬ìš©

```python
from peft import PeftModel
from transformers import AutoModelForCausalLM

# ê¸°ë³¸ ëª¨ë¸ ë¡œë“œ
base_model = AutoModelForCausalLM.from_pretrained("microsoft/DialoGPT-medium")

# LoRA ì–´ëŒ‘í„° ì ìš©
model = PeftModel.from_pretrained(base_model, "vlm_grpo_results/best_model")
```

## ðŸ› ï¸ ê³ ê¸‰ ì‚¬ìš©ë²•

### ì»¤ìŠ¤í…€ ì„¤ì • íŒŒì¼ ì‚¬ìš©

```bash
# JSON ì„¤ì • íŒŒì¼ ìƒì„±
cat > my_config.json << EOF
{
    "train_type": "lora",
    "lora_rank": 16,
    "lora_alpha": 64,
    "learning_rate": 2e-5,
    "num_iterations": 50
}
EOF

# ì„¤ì • íŒŒì¼ë¡œ ì‹¤í–‰
python vlm_grpo_system/run_enhanced_training.py --config my_config.json
```

### í”„ë¡œê·¸ëž˜ë° ë°©ì‹ ì‚¬ìš©

```python
from vlm_grpo_system.integration.main_trainer_enhanced import (
    EnhancedVLMGRPOSystem,
    create_lora_trainer,
    create_full_trainer
)

# LoRA íŠ¸ë ˆì´ë„ˆ ìƒì„±
trainer = create_lora_trainer(
    lora_rank=8,
    lora_alpha=32,
    learning_rate=1e-5,
    num_iterations=20
)

# ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™”
trainer.initialize_components()

# í•™ìŠµ ì‹¤í–‰
trainer.run_training()
```

## ðŸ› ë¬¸ì œ í•´ê²°

### ë©”ëª¨ë¦¬ ë¶€ì¡± ì˜¤ë¥˜

```bash
# ë°°ì¹˜ í¬ê¸° ì¤„ì´ê¸°
--per_device_train_batch_size 1
--gradient_accumulation_steps 4

# QLoRA ì‚¬ìš©
--train_type qlora

# ê·¸ëž˜ë””ì–¸íŠ¸ ì²´í¬í¬ì¸íŒ… í™œì„±í™”
--gradient_checkpointing
```

### Apple Silicon ê´€ë ¨ ì´ìŠˆ

```bash
# MPS í´ë°± ë¹„í™œì„±í™”
export PYTORCH_ENABLE_MPS_FALLBACK=0

# CPU ê°•ì œ ì‚¬ìš©
--device cpu
```

### CUDA ë©”ëª¨ë¦¬ ì˜¤ë¥˜

```bash
# ë©”ëª¨ë¦¬ ì •ë¦¬
export PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:128

# DeepSpeed ì‚¬ìš©
--use_deepspeed --deepspeed zero2
```

## ðŸ“ˆ ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬

| ì„¤ì •            | GPU ë©”ëª¨ë¦¬ | í•™ìŠµ ì‹œê°„ | ìµœì¢… ì„±ëŠ¥ | ì¶”ì²œë„     |
| --------------- | ---------- | --------- | --------- | ---------- |
| LoRA (rank=8)   | 6GB        | 100%      | 95%       | â­â­â­â­â­ |
| LoRA (rank=16)  | 8GB        | 110%      | 97%       | â­â­â­â­   |
| QLoRA (rank=16) | 4GB        | 130%      | 93%       | â­â­â­â­   |
| Full Training   | 16GB+      | 200%      | 100%      | â­â­â­     |

## ðŸ¤ ê¸°ì—¬í•˜ê¸°

1. ì´ìŠˆ ë¦¬í¬íŠ¸: ë²„ê·¸ë‚˜ ê°œì„ ì‚¬í•­ì„ GitHub Issuesì— ë“±ë¡
2. í’€ ë¦¬í€˜ìŠ¤íŠ¸: ìƒˆë¡œìš´ ê¸°ëŠ¥ì´ë‚˜ ë²„ê·¸ ìˆ˜ì • ì œì¶œ
3. ë¬¸ì„œ ê°œì„ : READMEë‚˜ ì½”ë“œ ì£¼ì„ ê°œì„ 

## ðŸ“š ì°¸ê³  ìžë£Œ

- [MS Swift CoZ GRPO](https://github.com/modelscope/swift) - ì›ë³¸ êµ¬í˜„
- [PEFT ë¼ì´ë¸ŒëŸ¬ë¦¬](https://github.com/huggingface/peft) - LoRA êµ¬í˜„
- [DeepSpeed](https://github.com/microsoft/DeepSpeed) - ë¶„ì‚° í•™ìŠµ
- [Weights & Biases](https://wandb.ai/) - ì‹¤í—˜ ì¶”ì 

## ðŸ“„ ë¼ì´ì„ ìŠ¤

ì´ í”„ë¡œì íŠ¸ëŠ” MIT ë¼ì´ì„ ìŠ¤ í•˜ì— ë°°í¬ë©ë‹ˆë‹¤.

---

**Enhanced VLM GRPO System** - MS Swift ìŠ¤íƒ€ì¼ì˜ ìœ ì—°í•˜ê³  íš¨ìœ¨ì ì¸ VLM í•™ìŠµ ì‹œìŠ¤í…œ
